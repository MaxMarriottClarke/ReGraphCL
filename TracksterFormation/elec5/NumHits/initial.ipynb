{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be01727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import glob\n",
    "\n",
    "import h5py\n",
    "import uproot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import awkward as ak\n",
    "import random\n",
    "from torch_geometric.nn import knn_graph\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9079592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import glob\n",
    "\n",
    "import h5py\n",
    "import uproot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import awkward as ak\n",
    "import random\n",
    "\n",
    "def find_highest_branch(path, base_name):\n",
    "    with uproot.open(path) as f:\n",
    "        # Find keys that exactly match the base_name (not containing other variations)\n",
    "        branches = [k for k in f.keys() if k.startswith(base_name + ';')]\n",
    "        \n",
    "        # Sort and select the highest-numbered branch\n",
    "        sorted_branches = sorted(branches, key=lambda x: int(x.split(';')[-1]))\n",
    "        return sorted_branches[-1] if sorted_branches else None\n",
    "class CCV1(Dataset):\n",
    "    r'''\n",
    "        input: layer clusters\n",
    "\n",
    "    '''\n",
    "\n",
    "    url = '/dummy/'\n",
    "\n",
    "    def __init__(self, root, transform=None, max_events=1e8, inp = 'train'):\n",
    "        super(CCV1, self).__init__(root, transform)\n",
    "        self.step_size = 500\n",
    "        self.inp = inp\n",
    "        self.max_events = max_events\n",
    "        self.fill_data(max_events)\n",
    "\n",
    "    def fill_data(self,max_events):\n",
    "        counter = 0\n",
    "        arrLens0 = []\n",
    "        arrLens1 = []\n",
    "\n",
    "        print(\"### Loading data\")\n",
    "        for fi,path in enumerate(tqdm.tqdm(self.raw_paths)):\n",
    "\n",
    "\n",
    "            if self.inp == 'train':\n",
    "                cluster_path = find_highest_branch(path, 'clusters')\n",
    "                sim_path = find_highest_branch(path, 'simtrackstersCP')\n",
    "            elif self.inp == 'val':\n",
    "                cluster_path = find_highest_branch(path, 'clusters')\n",
    "                sim_path = find_highest_branch(path, 'simtrackstersCP')\n",
    "            else:\n",
    "                cluster_path = find_highest_branch(path, 'clusters')\n",
    "                sim_path = find_highest_branch(path, 'simtrackstersCP')\n",
    "            \n",
    "            crosstree =  uproot.open(path)[cluster_path]\n",
    "            crosscounter = 0\n",
    "            for array in uproot.iterate(f\"{path}:{sim_path}\", [\"vertices_x\", \"vertices_y\", \"vertices_z\", \n",
    "            \"vertices_energy\", \"vertices_multiplicity\", \"vertices_time\", \"vertices_indexes\", \"barycenter_x\", \"barycenter_y\", \"barycenter_z\"], step_size=self.step_size):\n",
    "            \n",
    "                tmp_stsCP_vertices_x = array['vertices_x']\n",
    "                tmp_stsCP_vertices_y = array['vertices_y']\n",
    "                tmp_stsCP_vertices_z = array['vertices_z']\n",
    "                tmp_stsCP_vertices_energy = array['vertices_energy']\n",
    "                tmp_stsCP_vertices_time = array['vertices_time']\n",
    "                tmp_stsCP_vertices_indexes = array['vertices_indexes']\n",
    "                tmp_stsCP_barycenter_x = array['barycenter_x']\n",
    "                tmp_stsCP_barycenter_y = array['barycenter_y']\n",
    "                tmp_stsCP_barycenter_z = array['barycenter_z']\n",
    "\n",
    "\n",
    "                tmp_stsCP_vertices_multiplicity = array['vertices_multiplicity']\n",
    "                \n",
    "                # weighted energies (A LC appears in its caloparticle assignment array as the energy it contributes not full energy)\n",
    "                #tmp_stsCP_vertices_energy = tmp_stsCP_vertices_energy * tmp_stsCP_vertices_multiplicity\n",
    "                \n",
    "                self.step_size = min(self.step_size,len(tmp_stsCP_vertices_x))\n",
    "\n",
    "\n",
    "                # Code block for reading from other tree\n",
    "                tmp_all_vertices_layer_id = crosstree['cluster_layer_id'].array(entry_start=crosscounter*self.step_size,entry_stop=(crosscounter+1)*self.step_size)\n",
    "                #tmp_all_vertices_radius = crosstree['cluster_radius'].array(entry_start=crosscounter*self.step_size,entry_stop=(crosscounter+1)*self.step_size)\n",
    "                tmp_all_vertices_noh = crosstree['cluster_number_of_hits'].array(entry_start=crosscounter*self.step_size,entry_stop=(crosscounter+1)*self.step_size)\n",
    "                tmp_all_vertices_eta = crosstree['position_eta'].array(entry_start=crosscounter*self.step_size,entry_stop=(crosscounter+1)*self.step_size)\n",
    "                tmp_all_vertices_phi = crosstree['position_phi'].array(entry_start=crosscounter*self.step_size,entry_stop=(crosscounter+1)*self.step_size)\n",
    "                crosscounter += 1\n",
    "\n",
    "                layer_id_list = []\n",
    "                radius_list = []\n",
    "                noh_list = []\n",
    "                eta_list = []\n",
    "                phi_list = []\n",
    "                for evt_row in range(len(tmp_all_vertices_noh)):\n",
    "                    #print(\"Event no: %i\"%evt_row)\n",
    "                    #print(\"There are %i particles in this event\"%len(tmp_stsCP_vertices_indexes[evt_row]))\n",
    "                    layer_id_list_one_event = []\n",
    "                    #radius_list_one_event = []\n",
    "                    noh_list_one_event = []\n",
    "                    eta_list_one_event = []\n",
    "                    phi_list_one_event = []\n",
    "                    for particle in range(len(tmp_stsCP_vertices_indexes[evt_row])):\n",
    "                        #print(\"Particle no: %i\"%particle)\n",
    "                        #print(\"A\")\n",
    "                        #print(np.array(tmp_all_vertices_radius[evt_row]).shape)\n",
    "                        #print(\"B\")\n",
    "                        #print(np.array(tmp_stsCP_vertices_indexes[evt_row][particle]).shape)\n",
    "                        #print(\"C\")\n",
    "                        tmp_stsCP_vertices_layer_id_one_particle = tmp_all_vertices_layer_id[evt_row][tmp_stsCP_vertices_indexes[evt_row][particle]]\n",
    "                        #tmp_stsCP_vertices_radius_one_particle = tmp_all_vertices_radius[evt_row][tmp_stsCP_vertices_indexes[evt_row][particle]]\n",
    "                        tmp_stsCP_vertices_noh_one_particle = tmp_all_vertices_noh[evt_row][tmp_stsCP_vertices_indexes[evt_row][particle]]\n",
    "                        tmp_stsCP_vertices_eta_one_particle = tmp_all_vertices_eta[evt_row][tmp_stsCP_vertices_indexes[evt_row][particle]]\n",
    "                        tmp_stsCP_vertices_phi_one_particle = tmp_all_vertices_phi[evt_row][tmp_stsCP_vertices_indexes[evt_row][particle]]\n",
    "                        #print(tmp_stsCP_vertices_radius_one_particle)\n",
    "                        layer_id_list_one_event.append(tmp_stsCP_vertices_layer_id_one_particle)\n",
    "                        #radius_list_one_event.append(tmp_stsCP_vertices_radius_one_particle)\n",
    "                        noh_list_one_event.append(tmp_stsCP_vertices_noh_one_particle)\n",
    "                        eta_list_one_event.append(tmp_stsCP_vertices_eta_one_particle)\n",
    "                        phi_list_one_event.append(tmp_stsCP_vertices_phi_one_particle)\n",
    "                    layer_id_list.append(layer_id_list_one_event)\n",
    "                    #radius_list.append(radius_list_one_event)\n",
    "                    noh_list.append(noh_list_one_event)\n",
    "                    eta_list.append(eta_list_one_event)\n",
    "                    phi_list.append(phi_list_one_event)\n",
    "                tmp_stsCP_vertices_layer_id = ak.Array(layer_id_list)                \n",
    "                #tmp_stsCP_vertices_radius = ak.Array(radius_list)                \n",
    "                tmp_stsCP_vertices_noh = ak.Array(noh_list)                \n",
    "                tmp_stsCP_vertices_eta = ak.Array(eta_list)                \n",
    "                tmp_stsCP_vertices_phi = ak.Array(phi_list)                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                #SHOULD BE LEN(E) >= 2 for MULTI particles\n",
    "                skim_mask = []\n",
    "                for e in tmp_stsCP_vertices_x:\n",
    "                    if 2 <= len(e) <= 5: #<------ only train on samples with > 1 particle\n",
    "                        skim_mask.append(True)\n",
    "                    else:\n",
    "                        skim_mask.append(False)\n",
    "                tmp_stsCP_vertices_x = tmp_stsCP_vertices_x[skim_mask]\n",
    "                tmp_stsCP_vertices_y = tmp_stsCP_vertices_y[skim_mask]\n",
    "                tmp_stsCP_vertices_z = tmp_stsCP_vertices_z[skim_mask]\n",
    "                tmp_stsCP_vertices_energy = tmp_stsCP_vertices_energy[skim_mask]\n",
    "                tmp_stsCP_vertices_time = tmp_stsCP_vertices_time[skim_mask]\n",
    "                tmp_stsCP_vertices_layer_id = tmp_stsCP_vertices_layer_id[skim_mask]\n",
    "                #tmp_stsCP_vertices_radius = tmp_stsCP_vertices_radius[skim_mask]\n",
    "                tmp_stsCP_vertices_noh = tmp_stsCP_vertices_noh[skim_mask]\n",
    "                tmp_stsCP_vertices_eta = tmp_stsCP_vertices_eta[skim_mask]\n",
    "                tmp_stsCP_vertices_phi = tmp_stsCP_vertices_phi[skim_mask]\n",
    "                tmp_stsCP_vertices_indexes = tmp_stsCP_vertices_indexes[skim_mask]\n",
    "                tmp_stsCP_vertices_multiplicity = tmp_stsCP_vertices_multiplicity[skim_mask]\n",
    "\n",
    "                if counter == 0:\n",
    "                    self.stsCP_vertices_x = tmp_stsCP_vertices_x\n",
    "                    self.stsCP_vertices_y = tmp_stsCP_vertices_y\n",
    "                    self.stsCP_vertices_z = tmp_stsCP_vertices_z\n",
    "                    self.stsCP_vertices_energy = tmp_stsCP_vertices_energy\n",
    "                    self.stsCP_vertices_time = tmp_stsCP_vertices_time\n",
    "                    self.stsCP_vertices_layer_id = tmp_stsCP_vertices_layer_id\n",
    "                    #self.stsCP_vertices_radius = tmp_stsCP_vertices_radius\n",
    "                    self.stsCP_vertices_noh = tmp_stsCP_vertices_noh\n",
    "                    self.stsCP_vertices_eta = tmp_stsCP_vertices_eta\n",
    "                    self.stsCP_vertices_phi = tmp_stsCP_vertices_phi\n",
    "                    self.stsCP_vertices_indexes = tmp_stsCP_vertices_indexes\n",
    "                    self.stsCP_barycenter_x = tmp_stsCP_barycenter_x\n",
    "                    self.stsCP_barycenter_y = tmp_stsCP_barycenter_y\n",
    "                    self.stsCP_barycenter_z = tmp_stsCP_barycenter_z\n",
    "                    self.stsCP_vertices_multiplicity = tmp_stsCP_vertices_multiplicity\n",
    "                else:\n",
    "                    self.stsCP_vertices_x = ak.concatenate((self.stsCP_vertices_x,tmp_stsCP_vertices_x))\n",
    "                    self.stsCP_vertices_y = ak.concatenate((self.stsCP_vertices_y,tmp_stsCP_vertices_y))\n",
    "                    self.stsCP_vertices_z = ak.concatenate((self.stsCP_vertices_z,tmp_stsCP_vertices_z))\n",
    "                    self.stsCP_vertices_energy = ak.concatenate((self.stsCP_vertices_energy,tmp_stsCP_vertices_energy))\n",
    "                    self.stsCP_vertices_time = ak.concatenate((self.stsCP_vertices_time,tmp_stsCP_vertices_time))\n",
    "                    self.stsCP_vertices_layer_id = ak.concatenate((self.stsCP_vertices_layer_id,tmp_stsCP_vertices_layer_id))\n",
    "                    #self.stsCP_vertices_radius = ak.concatenate((self.stsCP_vertices_radius,tmp_stsCP_vertices_radius))\n",
    "                    self.stsCP_vertices_noh = ak.concatenate((self.stsCP_vertices_noh,tmp_stsCP_vertices_noh))\n",
    "                    self.stsCP_vertices_eta = ak.concatenate((self.stsCP_vertices_eta,tmp_stsCP_vertices_eta))\n",
    "                    self.stsCP_vertices_phi = ak.concatenate((self.stsCP_vertices_phi,tmp_stsCP_vertices_phi))\n",
    "                    self.stsCP_vertices_indexes = ak.concatenate((self.stsCP_vertices_indexes,tmp_stsCP_vertices_indexes))\n",
    "                    self.stsCP_barycenter_x = ak.concatenate((self.stsCP_barycenter_x,tmp_stsCP_barycenter_x))\n",
    "                    self.stsCP_barycenter_y = ak.concatenate((self.stsCP_barycenter_y,tmp_stsCP_barycenter_y))\n",
    "                    self.stsCP_barycenter_z = ak.concatenate((self.stsCP_barycenter_z,tmp_stsCP_barycenter_z))\n",
    "                    self.stsCP_vertices_multiplicity = ak.concatenate((self.stsCP_vertices_multiplicity, tmp_stsCP_vertices_multiplicity))\n",
    "\n",
    "                #print(len(self.stsCP_vertices_x))\n",
    "                counter += 1\n",
    "                if len(self.stsCP_vertices_x) > max_events:\n",
    "                    print(f\"Reached {max_events}!\")\n",
    "                    break\n",
    "            if len(self.stsCP_vertices_x) > max_events:\n",
    "                break\n",
    "     \n",
    "            \n",
    "            \n",
    "    def download(self):\n",
    "        raise RuntimeError(\n",
    "            'Dataset not found. Please download it from {} and move all '\n",
    "            '*.z files to {}'.format(self.url, self.raw_dir))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.stsCP_vertices_x)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_files = sorted(glob.glob(osp.join(self.raw_dir, '*.root')))\n",
    "        \n",
    "        #raw_files = [osp.join(self.raw_dir, 'step3_NTUPLE.root')]\n",
    "\n",
    "        return raw_files\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "    def get(self, idx):\n",
    "\n",
    "        # === Extract original grouped data ===\n",
    "        lc_x = self.stsCP_vertices_x[idx]\n",
    "        lc_y = self.stsCP_vertices_y[idx]\n",
    "        lc_z = self.stsCP_vertices_z[idx]\n",
    "        lc_e = self.stsCP_vertices_energy[idx]\n",
    "        lc_t = self.stsCP_vertices_time[idx]\n",
    "        lc_layer_id = self.stsCP_vertices_layer_id[idx]\n",
    "        lc_noh = self.stsCP_vertices_noh[idx]\n",
    "        lc_eta = self.stsCP_vertices_eta[idx]\n",
    "        lc_phi = self.stsCP_vertices_phi[idx]\n",
    "        lc_indexes = self.stsCP_vertices_indexes[idx]\n",
    "        lc_multiplicity = self.stsCP_vertices_multiplicity[idx]\n",
    "\n",
    "        # === Flatten the data arrays ===\n",
    "        flat_lc_x = np.expand_dims(np.array(ak.flatten(lc_x)), axis=1)\n",
    "        flat_lc_y = np.expand_dims(np.array(ak.flatten(lc_y)), axis=1)\n",
    "        flat_lc_z = np.expand_dims(np.array(ak.flatten(lc_z)), axis=1)\n",
    "        flat_lc_e = np.expand_dims(np.array(ak.flatten(lc_e)), axis=1)\n",
    "        flat_lc_t = np.expand_dims(np.array(ak.flatten(lc_t)), axis=1)\n",
    "        flat_lc_layer_id = np.expand_dims(np.array(ak.flatten(lc_layer_id)), axis=1)\n",
    "        flat_lc_noh = np.expand_dims(np.array(ak.flatten(lc_noh)), axis=1)\n",
    "        flat_lc_eta = np.expand_dims(np.array(ak.flatten(lc_eta)), axis=1)\n",
    "        flat_lc_phi = np.expand_dims(np.array(ak.flatten(lc_phi)), axis=1)\n",
    "        flat_lc_indexes = np.expand_dims(np.array(ak.flatten(lc_indexes)), axis=1)\n",
    "        flat_lc_multiplicity = np.expand_dims(np.array(ak.flatten(lc_multiplicity)), axis=1)\n",
    "\n",
    "        # === Create a flat group id array so that we know which original cluster each hit came from ===\n",
    "        flat_group_ids = []\n",
    "        for group_id, group in enumerate(lc_indexes):\n",
    "            group_np = np.array(group)\n",
    "            flat_group_ids.extend([group_id] * len(group_np))\n",
    "        flat_group_ids = np.array(flat_group_ids).reshape(-1, 1)\n",
    "\n",
    "\n",
    "        # === Build the mask ===\n",
    "        # First, mask repeated indices by keeping only the one with minimum multiplicity.\n",
    "        mask = np.zeros_like(flat_lc_indexes, dtype=bool)\n",
    "        for unique_idx in np.unique(flat_lc_indexes):\n",
    "            positions = np.where(flat_lc_indexes == unique_idx)[0]\n",
    "            if positions.size == 1:\n",
    "                mask[positions[0]] = True\n",
    "            else:\n",
    "                pos_to_keep = positions[np.argmin(flat_lc_multiplicity[positions])]\n",
    "                mask[pos_to_keep] = True\n",
    "\n",
    "        # Additional mask: only keep hits with number of hits (noh) > 1.\n",
    "        noh_mask = (flat_lc_noh > 1).flatten()\n",
    "        combined_mask = mask.flatten() & noh_mask\n",
    "\n",
    "        # === Apply the mask to all flattened arrays ===\n",
    "        flat_lc_x = flat_lc_x[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_y = flat_lc_y[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_z = flat_lc_z[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_e = flat_lc_e[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_t = flat_lc_t[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_layer_id = flat_lc_layer_id[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_noh = flat_lc_noh[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_eta = flat_lc_eta[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_phi = flat_lc_phi[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_indexes = flat_lc_indexes[combined_mask].reshape(-1, 1)\n",
    "        flat_lc_multiplicity = flat_lc_multiplicity[combined_mask].reshape(-1, 1)\n",
    "        flat_group_ids = flat_group_ids[combined_mask].reshape(-1, 1)\n",
    "        \n",
    "\n",
    "           # === Reset all multiplicities to 1 ===\n",
    "        flat_lc_multiplicity = np.ones_like(flat_lc_multiplicity)\n",
    "\n",
    "        # === Create positive edges (x_pe) using flat_group_ids ===\n",
    "        # For each node (i) that is in a group with at least one other node,\n",
    "        # randomly select one positive partner (j) from the same group.\n",
    "        flat_group_ids_flat = flat_group_ids.flatten()\n",
    "        pos_edges = []\n",
    "        for group in np.unique(flat_group_ids_flat):\n",
    "            indices = np.where(flat_group_ids_flat == group)[0]\n",
    "            if len(indices) < 2:\n",
    "                continue\n",
    "            for i in indices:\n",
    "                # Choose one random candidate from the same group (but not the node itself)\n",
    "                candidates = indices[indices != i]\n",
    "                chosen = np.random.choice(candidates)\n",
    "                pos_edges.append([i, chosen])\n",
    "        if len(pos_edges) > 0:\n",
    "            x_pe = torch.tensor(np.array(pos_edges), dtype=torch.long)\n",
    "        else:\n",
    "            x_pe = torch.empty((0, 2), dtype=torch.long)\n",
    "\n",
    "        # === Create the feature tensor ===\n",
    "        flat_lc_feats = np.concatenate(\n",
    "            (flat_lc_x, flat_lc_y, flat_lc_z, flat_lc_e, flat_lc_layer_id, flat_lc_noh, flat_lc_eta, flat_lc_phi),\n",
    "            axis=-1\n",
    "        )\n",
    "        x = torch.from_numpy(flat_lc_feats).float()\n",
    "\n",
    "        return Data(x=x, assoc=flat_group_ids.flatten().tolist(), x_pe=x_pe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cba6fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/3 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100!\n",
      "### Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/1 [00:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ipath = \"/vols/cms/mm1221/Data/100k/5e/train/\"\n",
    "vpath = \"/vols/cms/mm1221/Data/100k/5e/val/\"\n",
    "data_train = CCV1(ipath, max_events=100, inp = 'train')\n",
    "data_val = CCV1(vpath, max_events=100, inp='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c32db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   9],\n",
      "        [  1,  16],\n",
      "        [  2,   9],\n",
      "        [  3,  28],\n",
      "        [  4,   0],\n",
      "        [  5,  17],\n",
      "        [  6,  20],\n",
      "        [  7,  20],\n",
      "        [  8,   2],\n",
      "        [  9,  29],\n",
      "        [ 10,  29],\n",
      "        [ 11,   1],\n",
      "        [ 12,  13],\n",
      "        [ 13,  28],\n",
      "        [ 14,  20],\n",
      "        [ 15,  11],\n",
      "        [ 16,  21],\n",
      "        [ 17,  20],\n",
      "        [ 18,   4],\n",
      "        [ 19,  23],\n",
      "        [ 20,  27],\n",
      "        [ 21,  10],\n",
      "        [ 22,  17],\n",
      "        [ 23,  25],\n",
      "        [ 24,   4],\n",
      "        [ 25,  29],\n",
      "        [ 26,  21],\n",
      "        [ 27,   0],\n",
      "        [ 28,   6],\n",
      "        [ 29,   6],\n",
      "        [ 30,  12],\n",
      "        [ 31,  50],\n",
      "        [ 32,  41],\n",
      "        [ 33,  52],\n",
      "        [ 34,  39],\n",
      "        [ 35,  47],\n",
      "        [ 36,  53],\n",
      "        [ 37,  58],\n",
      "        [ 38,  32],\n",
      "        [ 39,  61],\n",
      "        [ 40,  58],\n",
      "        [ 41,  53],\n",
      "        [ 42,  39],\n",
      "        [ 43,  60],\n",
      "        [ 44,  61],\n",
      "        [ 45,  64],\n",
      "        [ 46,  63],\n",
      "        [ 47,  33],\n",
      "        [ 48,  41],\n",
      "        [ 49,  37],\n",
      "        [ 50,  48],\n",
      "        [ 51,  64],\n",
      "        [ 52,  42],\n",
      "        [ 53,  31],\n",
      "        [ 54,  40],\n",
      "        [ 55,  57],\n",
      "        [ 56,  58],\n",
      "        [ 57,  51],\n",
      "        [ 58,  53],\n",
      "        [ 59,  45],\n",
      "        [ 60,  36],\n",
      "        [ 61,  60],\n",
      "        [ 62,  39],\n",
      "        [ 63,  60],\n",
      "        [ 64,  38],\n",
      "        [ 65,  31],\n",
      "        [ 66,  76],\n",
      "        [ 67,  89],\n",
      "        [ 68,  76],\n",
      "        [ 69,  84],\n",
      "        [ 70, 102],\n",
      "        [ 71,  74],\n",
      "        [ 72,  97],\n",
      "        [ 73,  66],\n",
      "        [ 74,  87],\n",
      "        [ 75,  85],\n",
      "        [ 76,  78],\n",
      "        [ 77,  94],\n",
      "        [ 78,  84],\n",
      "        [ 79,  85],\n",
      "        [ 80,  77],\n",
      "        [ 81, 102],\n",
      "        [ 82,  87],\n",
      "        [ 83,  80],\n",
      "        [ 84,  98],\n",
      "        [ 85,  71],\n",
      "        [ 86, 100],\n",
      "        [ 87,  74],\n",
      "        [ 88, 106],\n",
      "        [ 89,  84],\n",
      "        [ 90,  76],\n",
      "        [ 91,  87],\n",
      "        [ 92,  76],\n",
      "        [ 93,  77],\n",
      "        [ 94,  82],\n",
      "        [ 95,  66],\n",
      "        [ 96,  67],\n",
      "        [ 97,  72],\n",
      "        [ 98, 102],\n",
      "        [ 99, 100],\n",
      "        [100,  80],\n",
      "        [101,  96],\n",
      "        [102,  96],\n",
      "        [103,  87],\n",
      "        [104,  92],\n",
      "        [105,  93],\n",
      "        [106,  97]])\n"
     ]
    }
   ],
   "source": [
    "print(data_train[0].x_pe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45344fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3474ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "# Initialize model with passed hyperparameters\n",
    "model = Net(\n",
    "    hidden_dim=128,\n",
    "    dropout=0.3,\n",
    "    k_value = 24,\n",
    "    contrastive_dim=128\n",
    ")\n",
    "k_value = 24\n",
    "BS = 1\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef530f66",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7c4f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import glob\n",
    "\n",
    "import h5py\n",
    "import uproot\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import awkward as ak\n",
    "import random\n",
    "from torch_geometric.nn import knn_graph\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss_curriculum_both(embeddings, group_ids, temperature=0.1, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Computes an NT-Xent style loss that blends both positive and negative mining.\n",
    "    \n",
    "    For each anchor i:\n",
    "      - Deterministically select one positive index j (j != i) such that group_ids[j]==group_ids[i],\n",
    "        using a pseudo-random hash function. This ensures that each time the same event is\n",
    "        processed, the same positive is chosen.\n",
    "      - Hard negative similarity: max { sim(embeddings[i], embeddings[j]) : group_ids[j] != group_ids[i] }\n",
    "      - Random negative similarity: similarity from a randomly chosen negative (group_ids differ)\n",
    "      - Blended negative similarity: blended_neg = (1 - alpha) * rand_neg_sim + alpha * hard_neg_sim\n",
    "      \n",
    "    The loss per anchor is then:\n",
    "         loss_i = - log( exp(positive_sim/temperature) / [ exp(positive_sim/temperature) + exp(blended_neg/temperature) ] )\n",
    "    \n",
    "    Anchors that lack any valid positives or negatives contribute 0.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Tensor of shape (N, D) (raw outputs; they will be normalized inside).\n",
    "        group_ids: 1D Tensor (length N) of group identifiers.\n",
    "        temperature: Temperature scaling factor.\n",
    "        alpha: Blending parameter for negatives (0: use only random, 1: use only hard).\n",
    "        \n",
    "    Returns:\n",
    "        Scalar loss (mean over anchors).\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize embeddings so cosine similarity is the dot product.\n",
    "    norm_emb = F.normalize(embeddings, p=2, dim=1)  # shape (N, D)\n",
    "    sim_matrix = norm_emb @ norm_emb.t()             # shape (N, N)\n",
    "\n",
    "    N = embeddings.size(0)\n",
    "    idx = torch.arange(N, device=embeddings.device)\n",
    "\n",
    "    # --- Positives ---\n",
    "    # Build positive mask: same group and not self.\n",
    "    pos_mask = (group_ids.unsqueeze(1) == group_ids.unsqueeze(0))\n",
    "    pos_mask = pos_mask & ~torch.eye(N, dtype=torch.bool, device=embeddings.device)\n",
    "    valid_pos_counts = pos_mask.sum(dim=1)\n",
    "    no_valid_pos = (valid_pos_counts == 0)\n",
    "    \n",
    "    # Instead of using a fresh random tensor each time,\n",
    "    # we create a deterministic pseudo-random matrix that depends on:\n",
    "    #   - The anchor index (i)\n",
    "    #   - The candidate index (j)\n",
    "    #   - The group id of the anchor (to make it event-specific)\n",
    "    # The constants (12.9898, 78.233, 37.719, and 43758.5453) are arbitrary and can be tuned.\n",
    "    i_indices = torch.arange(N, device=embeddings.device).unsqueeze(1).float()  # shape (N, 1)\n",
    "    j_indices = torch.arange(N, device=embeddings.device).unsqueeze(0).float()  # shape (1, N)\n",
    "    group_ids_float = group_ids.float().unsqueeze(1)  # shape (N, 1)\n",
    "    \n",
    "    deterministic_rand = torch.sin(i_indices * 12.9898 + j_indices * 78.233 + group_ids_float * 37.719) * 43758.5453\n",
    "    deterministic_rand = deterministic_rand - deterministic_rand.floor()  # take fractional part\n",
    "    # Now mask out invalid (non-positive) entries.\n",
    "    pos_rand_vals = deterministic_rand * pos_mask.float() - (1 - pos_mask.float())\n",
    "    pos_indices = torch.argmax(pos_rand_vals, dim=1)\n",
    "    pos_sim = sim_matrix[idx, pos_indices]\n",
    "    # For anchors without any valid positive, set similarity to 0.\n",
    "    pos_sim = torch.where(no_valid_pos, torch.tensor(0.0, device=embeddings.device), pos_sim)\n",
    "    \n",
    "    # Use this deterministically selected positive similarity as the positive term.\n",
    "    blended_pos = pos_sim\n",
    "\n",
    "    # --- Negatives ---\n",
    "    # Build negative mask: indices with different group_ids.\n",
    "    neg_mask = (group_ids.unsqueeze(1) != group_ids.unsqueeze(0))\n",
    "    valid_neg_counts = neg_mask.sum(dim=1)\n",
    "    no_valid_neg = (valid_neg_counts == 0)\n",
    "    \n",
    "    # Random negative: randomly sample one negative index per anchor.\n",
    "    rand_vals = torch.rand(sim_matrix.shape, device=embeddings.device)\n",
    "    rand_vals = rand_vals * neg_mask.float() - (1 - neg_mask.float())\n",
    "    rand_neg_indices = torch.argmax(rand_vals, dim=1)\n",
    "    rand_neg_sim = sim_matrix[idx, rand_neg_indices]\n",
    "    \n",
    "    # Hard negative: for each anchor, choose the negative with maximum similarity.\n",
    "    sim_matrix_neg = sim_matrix.masked_fill(~neg_mask, -float('inf'))\n",
    "    hard_neg_sim, _ = sim_matrix_neg.max(dim=1)\n",
    "    hard_neg_sim = torch.where(no_valid_neg, torch.tensor(-1.0, device=embeddings.device), hard_neg_sim)\n",
    "    \n",
    "    # Blend the negatives.\n",
    "    blended_neg = (1 - alpha) * rand_neg_sim + alpha * hard_neg_sim\n",
    "\n",
    "    # Compute loss per anchor.\n",
    "    loss = -torch.log(torch.exp(blended_pos / temperature) / (torch.exp(blended_neg / temperature) + torch.exp(blended_pos / temperature)))\n",
    "    # For anchors with no valid negatives, set loss to 0.\n",
    "    loss = loss.masked_fill(no_valid_neg, 0.0)\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss_curriculum(embeddings, group_ids, temperature=0.1, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Curriculum loss that uses both positive and negative blending.\n",
    "    \n",
    "    Delegates to contrastive_loss_curriculum_both.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Tensor of shape (N, D).\n",
    "        pos_indices: 1D Tensor (length N).\n",
    "        group_ids: 1D Tensor (length N).\n",
    "        temperature: Temperature scaling factor.\n",
    "        alpha: Blending parameter.\n",
    "        \n",
    "    Returns:\n",
    "        Scalar loss.\n",
    "    \"\"\"\n",
    "    return contrastive_loss_curriculum_both(embeddings, group_ids, temperature, alpha)\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train_new(train_loader, model, optimizer, device, k_value, alpha):\n",
    "    model.train()\n",
    "    total_loss = torch.zeros(1, device=device)\n",
    "    for data in tqdm(train_loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data.assoc to tensor if needed.\n",
    "        if isinstance(data.assoc, list):\n",
    "            if isinstance(data.assoc[0], list):\n",
    "                assoc_tensor = torch.cat([torch.tensor(a, dtype=torch.int64, device=data.x.device)\n",
    "                                          for a in data.assoc])\n",
    "            else:\n",
    "                assoc_tensor = torch.tensor(data.assoc, device=data.x.device)\n",
    "        else:\n",
    "            assoc_tensor = data.assoc\n",
    "\n",
    "        embeddings, _ = model(data.x, data.x_batch)\n",
    "        \n",
    "        # Partition batch by event.\n",
    "        batch_np = data.x_batch.detach().cpu().numpy()\n",
    "        _, counts = np.unique(batch_np, return_counts=True)\n",
    "        \n",
    "        loss_event_total = torch.zeros(1, device=device)\n",
    "        start_idx = 0\n",
    "        for count in counts:\n",
    "            end_idx = start_idx + count\n",
    "            event_embeddings = embeddings[start_idx:end_idx]\n",
    "            event_group_ids = assoc_tensor[start_idx:end_idx]\n",
    "            loss_event = contrastive_loss_curriculum(event_embeddings,\n",
    "                                                     event_group_ids, temperature=0.5, alpha=alpha)\n",
    "            loss_event_total += loss_event\n",
    "            start_idx = end_idx\n",
    "        \n",
    "        loss = loss_event_total / len(counts)\n",
    "        loss.backward()\n",
    "        total_loss += loss\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_new(test_loader, model, device, k_value, alpha):\n",
    "    model.eval()\n",
    "    total_loss = torch.zeros(1, device=device)\n",
    "    for data in tqdm(test_loader, desc=\"Validation\"):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        if isinstance(data.assoc, list):\n",
    "            if isinstance(data.assoc[0], list):\n",
    "                assoc_tensor = torch.cat([torch.tensor(a, dtype=torch.int64, device=data.x.device)\n",
    "                                          for a in data.assoc])\n",
    "            else:\n",
    "                assoc_tensor = torch.tensor(data.assoc, device=data.x.device)\n",
    "        else:\n",
    "            assoc_tensor = data.assoc\n",
    "        \n",
    "        embeddings, _ = model(data.x, data.x_batch)\n",
    "        \n",
    "        batch_np = data.x_batch.detach().cpu().numpy()\n",
    "        _, counts = np.unique(batch_np, return_counts=True)\n",
    "        \n",
    "        loss_event_total = torch.zeros(1, device=device)\n",
    "        start_idx = 0\n",
    "        for count in counts:\n",
    "            end_idx = start_idx + count\n",
    "            event_embeddings = embeddings[start_idx:end_idx]\n",
    "            event_group_ids = assoc_tensor[start_idx:end_idx]\n",
    "            loss_event = contrastive_loss_curriculum(event_embeddings,\n",
    "                                                     event_group_ids, temperature=0.5, alpha=0)\n",
    "            loss_event_total += loss_event\n",
    "            start_idx = end_idx\n",
    "        total_loss += loss_event_total / len(counts)\n",
    "    return total_loss / len(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebfbb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_curriculum_both(embeddings, pos_indices, group_ids, temperature=0.5, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Computes an NT-Xent style loss that blends both positive and negative mining.\n",
    "    \n",
    "    For each anchor i:\n",
    "      - Provided positive similarity: pos_sim_orig = sim(embeddings[i], embeddings[pos_indices[i]])\n",
    "      - Hard positive similarity: hard_pos_sim = min { sim(embeddings[i], embeddings[j]) : \n",
    "                                                      j != i and group_ids[j] == group_ids[i] }\n",
    "      - Blended positive similarity: blended_pos = (1 - alpha) * pos_sim_orig + alpha * hard_pos_sim\n",
    "      - Random negative similarity: rand_neg_sim = similarity from a randomly chosen negative (group_ids differ)\n",
    "      - Hard negative similarity: hard_neg_sim = max { sim(embeddings[i], embeddings[j]) : \n",
    "                                                      group_ids[j] != group_ids[i] }\n",
    "      - Blended negative similarity: blended_neg = (1 - alpha) * rand_neg_sim + alpha * hard_neg_sim\n",
    "      \n",
    "    The loss per anchor is then:\n",
    "         loss_i = - log( exp(blended_pos/temperature) / [ exp(blended_pos/temperature) + exp(blended_neg/temperature) ] )\n",
    "    \n",
    "    Anchors that lack any valid positives or negatives contribute 0.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Tensor of shape (N, D) (raw outputs; they will be normalized inside).\n",
    "        pos_indices: 1D Tensor (length N) giving the index of the provided positive for each anchor.\n",
    "        group_ids: 1D Tensor (length N) of group identifiers.\n",
    "        temperature: Temperature scaling factor.\n",
    "        alpha: Blending parameter between random and hard mining (0: use only provided/random, 1: use only hard).\n",
    "        \n",
    "    Returns:\n",
    "        Scalar loss (mean over anchors).\n",
    "    \"\"\"\n",
    "    # Normalize embeddings so that cosine similarity is simply the dot product.\n",
    "    norm_emb = F.normalize(embeddings, p=2, dim=1)  # shape (N, D)\n",
    "    # Compute full cosine similarity matrix.\n",
    "    sim_matrix = norm_emb @ norm_emb.t()  # shape (N, N)\n",
    "    N = embeddings.size(0)\n",
    "    idx = torch.arange(N, device=embeddings.device)\n",
    "    \n",
    "    # --- Positives ---\n",
    "    # Provided positive similarity.\n",
    "    pos_sim_orig = sim_matrix[idx, pos_indices.view(-1)]\n",
    "    \"\"\"\n",
    "    # Hard positive: consider all other indices in the same group.\n",
    "    pos_mask = (group_ids.unsqueeze(1) == group_ids.unsqueeze(0))\n",
    "    # Exclude self (set diagonal to False)\n",
    "    pos_mask = pos_mask & ~torch.eye(N, dtype=torch.bool, device=embeddings.device)\n",
    "    # For each anchor, if there are valid positives, take the minimum similarity.\n",
    "    # To do that, copy sim_matrix and set invalid positions to a large number (e.g., 2.0).\n",
    "    sim_matrix_pos = sim_matrix.clone()\n",
    "    sim_matrix_pos[~pos_mask] = 2.0  # cosine similarity <= 1, so 2 is safe.\n",
    "    hard_pos_sim, _ = sim_matrix_pos.min(dim=1)\n",
    "    # If an anchor has no valid positive (should not happen if each group has >= 2 items), fallback to provided.\n",
    "    valid_pos_counts = pos_mask.sum(dim=1)\n",
    "    no_valid_pos = (valid_pos_counts == 0)\n",
    "    hard_pos_sim = torch.where(no_valid_pos, pos_sim_orig, hard_pos_sim)\n",
    "    \"\"\"\n",
    "    # Blended positive similarity.\n",
    "    blended_pos =  pos_sim_orig \n",
    "    \n",
    "    # --- Negatives ---\n",
    "    # Mask for negatives: group_ids differ.\n",
    "    neg_mask = (group_ids.unsqueeze(1) != group_ids.unsqueeze(0))\n",
    "    valid_neg_counts = neg_mask.sum(dim=1)\n",
    "    # For anchors with no valid negatives, we later set loss to 0.\n",
    "    no_valid_neg = (valid_neg_counts == 0)\n",
    "    \n",
    "    # Random negative: for each anchor, select one random index among negatives.\n",
    "    rand_vals = torch.rand(sim_matrix.shape, device=embeddings.device)\n",
    "    rand_vals = rand_vals * neg_mask.float() - (1 - neg_mask.float())\n",
    "    rand_neg_indices = torch.argmax(rand_vals, dim=1)\n",
    "    rand_neg_sim = sim_matrix[idx, rand_neg_indices]\n",
    "    \n",
    "    # Hard negative: among all negatives, choose the one with maximum similarity.\n",
    "    sim_matrix_neg = sim_matrix.masked_fill(~neg_mask, -float('inf'))\n",
    "    hard_neg_sim, _ = sim_matrix_neg.max(dim=1)\n",
    "    # For anchors with no valid negatives, use -1.\n",
    "    hard_neg_sim = torch.where(no_valid_neg, torch.tensor(-1.0, device=embeddings.device), hard_neg_sim)\n",
    "    \n",
    "    # Blended negative similarity.\n",
    "    blended_neg = (1 - alpha) * rand_neg_sim + alpha * hard_neg_sim\n",
    "    \n",
    "    # --- Loss Computation ---\n",
    "    loss = -torch.log(\n",
    "    torch.exp(blended_pos / temperature) / \n",
    "    (torch.exp(blended_pos / temperature) + torch.exp(blended_neg / temperature)))\n",
    "    # For anchors with no valid negatives, set loss to 0.\n",
    "    loss = loss.masked_fill(no_valid_neg, 0.0)\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def contrastive_loss_curriculum(embeddings, pos_indices, group_ids, temperature=0.5, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Curriculum loss that uses both positive and negative blending.\n",
    "    \n",
    "    Delegates to contrastive_loss_curriculum_both.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Tensor of shape (N, D).\n",
    "        pos_indices: 1D Tensor (length N).\n",
    "        group_ids: 1D Tensor (length N).\n",
    "        temperature: Temperature scaling factor.\n",
    "        alpha: Blending parameter.\n",
    "        \n",
    "    Returns:\n",
    "        Scalar loss.\n",
    "    \"\"\"\n",
    "    return contrastive_loss_curriculum_both(embeddings, pos_indices, group_ids, temperature, alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "# Training and Testing Functions\n",
    "#################################\n",
    "\n",
    "def train_new(train_loader, model, optimizer, device, k_value, alpha):\n",
    "    model.train()\n",
    "    total_loss = torch.zeros(1, device=device)\n",
    "    for data in tqdm(train_loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data.assoc to tensor if needed.\n",
    "        if isinstance(data.assoc, list):\n",
    "            if isinstance(data.assoc[0], list):\n",
    "                assoc_tensor = torch.cat([torch.tensor(a, dtype=torch.int64, device=data.x.device)\n",
    "                                          for a in data.assoc])\n",
    "            else:\n",
    "                assoc_tensor = torch.tensor(data.assoc, device=data.x.device)\n",
    "        else:\n",
    "            assoc_tensor = data.assoc\n",
    "\n",
    "\n",
    "        embeddings, _ = model(data.x, data.x_batch)\n",
    "        \n",
    "        # Partition batch by event.\n",
    "        batch_np = data.x_batch.detach().cpu().numpy()\n",
    "        _, counts = np.unique(batch_np, return_counts=True)\n",
    "        \n",
    "        loss_event_total = torch.zeros(1, device=device)\n",
    "        start_idx = 0\n",
    "        for count in counts:\n",
    "            end_idx = start_idx + count\n",
    "            event_embeddings = embeddings[start_idx:end_idx]\n",
    "            event_group_ids = assoc_tensor[start_idx:end_idx]\n",
    "            event_pos_indices = data.x_pe[start_idx:end_idx, 1].view(-1)\n",
    "            loss_event = contrastive_loss_curriculum(event_embeddings, event_pos_indices,\n",
    "                                                     event_group_ids, temperature=0.5, alpha=alpha)\n",
    "            loss_event_total += loss_event\n",
    "            start_idx = end_idx\n",
    "        \n",
    "        loss = loss_event_total / len(counts)\n",
    "        loss.backward()\n",
    "        total_loss += loss\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_new(test_loader, model, device, k_value):\n",
    "    model.eval()\n",
    "    total_loss = torch.zeros(1, device=device)\n",
    "    for data in tqdm(test_loader, desc=\"Validation\"):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        if isinstance(data.assoc, list):\n",
    "            if isinstance(data.assoc[0], list):\n",
    "                assoc_tensor = torch.cat([torch.tensor(a, dtype=torch.int64, device=data.x.device)\n",
    "                                          for a in data.assoc])\n",
    "            else:\n",
    "                assoc_tensor = torch.tensor(data.assoc, device=data.x.device)\n",
    "        else:\n",
    "            assoc_tensor = data.assoc\n",
    "        \n",
    "\n",
    "        embeddings, _ = model(data.x, data.x_batch)\n",
    "        \n",
    "        batch_np = data.x_batch.detach().cpu().numpy()\n",
    "        _, counts = np.unique(batch_np, return_counts=True)\n",
    "        \n",
    "        loss_event_total = torch.zeros(1, device=device)\n",
    "        start_idx = 0\n",
    "        for count in counts:\n",
    "            end_idx = start_idx + count\n",
    "            event_embeddings = embeddings[start_idx:end_idx]\n",
    "            event_group_ids = assoc_tensor[start_idx:end_idx]\n",
    "            event_pos_indices = data.x_pe[start_idx:end_idx, 1].view(-1)\n",
    "            loss_event = contrastive_loss_curriculum(event_embeddings, event_pos_indices,\n",
    "                                                     event_group_ids, temperature=0.5, alpha=0)\n",
    "            loss_event_total += loss_event\n",
    "            start_idx = end_idx\n",
    "        total_loss += loss_event_total / len(counts)\n",
    "    return total_loss / len(test_loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe8d89dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Alpha: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:30<00:00, 13.78it/s]\n",
      "Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 408/408 [00:17<00:00, 22.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.69321740, Validation Loss: 0.69314593\n",
      "Epoch 2/20 | Alpha: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:30<00:00, 13.71it/s]\n",
      "Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 408/408 [00:17<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.69315267, Validation Loss: 0.69314593\n",
      "Epoch 3/20 | Alpha: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:29<00:00, 14.16it/s]\n",
      "Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 408/408 [00:17<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.69314778, Validation Loss: 0.69314593\n",
      "Epoch 4/20 | Alpha: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:30<00:00, 13.64it/s]\n",
      "Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 408/408 [00:17<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.69320118, Validation Loss: 0.69314593\n",
      "Epoch 5/20 | Alpha: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:31<00:00, 13.46it/s]\n",
      "Validation:   6%|████████▌                                                                                                                             | 26/408 [00:01<00:17, 22.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1344772/526583528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs} | Alpha: {alpha:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1344772/2942411208.py\u001b[0m in \u001b[0;36mtest_new\u001b[0;34m(test_loader, model, device, k_value)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mbatch_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vols/cms/mm1221/hgcal/elec5New/LC/NumHits/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_lc, batch_lc)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mfeats1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lc_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lc_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_lc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_lc_enc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mfeats2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_lc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeats1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mfeats3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_lc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeats2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch_geometric/nn/conv/edge_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# propagate_type: (x: PairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cpu')\n",
    "# Load DataLoader with current batch_size\n",
    "train_loader = DataLoader(data_train, batch_size=BS, shuffle=True, follow_batch=['x'])\n",
    "val_loader = DataLoader(data_val, batch_size=BS, shuffle=False, follow_batch=['x'])\n",
    "\n",
    "# Train and evaluate the model for the specified number of epochs\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Store train and validation losses for all epochs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "output_dir = '/vols/cms/mm1221/hgcal/elec5New/LC/NegativeMining/results/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "epochs = 20\n",
    "patience = 20\n",
    "for epoch in range(epochs):\n",
    "    # For epochs 1 to 150, gradually increase alpha from 0 to 1.\n",
    "    # From epoch 151 onward, set alpha = 1 (fully hard negatives).\n",
    "    if epoch < 10:\n",
    "        alpha = 0\n",
    "    else:\n",
    "        alpha = 0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Alpha: {alpha:.2f}\")\n",
    "    train_loss = train_new(train_loader, model, optimizer, device, k_value, alpha)\n",
    "    val_loss = test_new(val_loader, model, device, k_value)\n",
    "\n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save best model if validation loss improves.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pt'))\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    # Save intermediate checkpoint.\n",
    "    state_dicts = {'model': model.state_dict(),\n",
    "                   'opt': optimizer.state_dict(),\n",
    "                   'lr': scheduler.state_dict()}\n",
    "    torch.save(state_dicts, os.path.join(output_dir, f'epoch-{epoch+1}.pt'))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.item():.8f}, Validation Loss: {val_loss.item():.8f}\")\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# Save training history.\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame({\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses\n",
    "})\n",
    "results_df.to_csv(os.path.join(output_dir, 'continued_training_loss.csv'), index=False)\n",
    "print(f\"Saved loss curves to {os.path.join(output_dir, 'continued_training_loss.csv')}\")\n",
    "\n",
    "# Save final model.\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, 'final_model.pt'))\n",
    "print(\"Training complete. Final model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e22b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(data_train[0].assoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2eb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
