{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a22c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: imports\n",
    "\n",
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from dataAnalyse import CCV1\n",
    "from torch_geometric.data import DataLoader \n",
    "from model import Net\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from Imports import Aggloremative, calculate_reco_to_sim_score, calculate_sim_to_reco_score, calculate_all_event_scores\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddde4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading tracksters data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vols/cms/mm1221/Data/le2e/raw/step3_NTUPLE.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/1 [00:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 10000 events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "#1: Load Data + Model\n",
    "#1.1: Load Data Through the dataloader - used for predictions\n",
    "testpath = \"/vols/cms/mm1221/Data/le2e/\"\n",
    "data_test = CCV1(testpath, max_events=10000, inp = 'test')\n",
    "test_loader = DataLoader(data_test, batch_size=1, shuffle=False, follow_batch=['x'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484d908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lc_encode): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x CustomStaticEdgeConv(\n",
       "      (nn_module): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ELU(alpha=1.0)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model \n",
    "model = Net(\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    dropout=0.3,\n",
    "    contrastive_dim=16\n",
    ")\n",
    "\n",
    "\n",
    "#checkpoint= torch.load('/vols/cms/mm1221/hgcal/elec5New/Track/NegativeMining/resultslr5t54SECEXT/best_model.pt',  map_location=torch.device('cpu'))\n",
    "checkpoint= torch.load('/vols/cms/mm1221/hgcal/elec5New/Track/NegativeMining/resultsSECNeg/best_model.pt',  map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(checkpoint)  \n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a404da0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "average inference time: 0.10265118802957866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#3: Make Predictions + Cluster -> Calculate the inference time\n",
    "#3.1: Make Predictions\n",
    "\n",
    "all_predictions = []  \n",
    "total_times = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, data in enumerate(data_test):\n",
    "\n",
    "    print(i)\n",
    "    if i> 200:\n",
    "        break\n",
    "    edge_index = knn_graph(data.x, k=16)  \n",
    "    predictions = model(data.x, edge_index, 1)\n",
    "    all_predictions.append(predictions[0].detach().cpu().numpy())  \n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "#3.2: Cluster using threshold found in Script A\n",
    "\n",
    "all_cluster_labels = Aggloremative(all_predictions, threshold = 0.18)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "#3.3: Calculate average inference time\n",
    "\n",
    "time_diff = end_time - start_time\n",
    "inference_time = time_diff/len(all_cluster_labels)\n",
    "print(\"average inference time:\", inference_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f299c390",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyInFileError",
     "evalue": "not found: 'simtrackstersCP' with cycle 1\n\n    Available keys: 'ticlDumper/simtrackstersCP;1', 'ticlDumper/tracksters;1', 'ticlDumper/simtrackstersSC;1', 'ticlDumper/clusters;1', 'ticlDumper/tracks;1', 'ticlDumper;1', 'ticlDumper/trackstersMerged;1', 'ticlDumper/candidates;1'...\n\nin file /vols/cms/mm1221/Data/le2e/raw/step3_NTUPLE.root",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyInFileError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3526953/2035620039.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticlDumper/associations;1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tsCLUE3D_recoToSim_CP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mTrueEnergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'simtrackstersCP;1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regressed_energy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/uproot/reading.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2107\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2109\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/uproot/reading.py\u001b[0m in \u001b[0;36mkey\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m   2059\u001b[0m             )\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             raise uproot.KeyInFileError(\n\u001b[0m\u001b[1;32m   2062\u001b[0m                 \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             )\n",
      "\u001b[0;31mKeyInFileError\u001b[0m: not found: 'simtrackstersCP' with cycle 1\n\n    Available keys: 'ticlDumper/simtrackstersCP;1', 'ticlDumper/tracksters;1', 'ticlDumper/simtrackstersSC;1', 'ticlDumper/clusters;1', 'ticlDumper/tracks;1', 'ticlDumper;1', 'ticlDumper/trackstersMerged;1', 'ticlDumper/candidates;1'...\n\nin file /vols/cms/mm1221/Data/le2e/raw/step3_NTUPLE.root"
     ]
    }
   ],
   "source": [
    "# Also load explicitely, used for analysis and plots\n",
    "data_path = '/vols/cms/mm1221/Data/le2e/raw/step3_NTUPLE.root'\n",
    "data_file = uproot.open(data_path)\n",
    "\n",
    "ass = data_file['ticlDumper/associations;1']['tsCLUE3D_recoToSim_CP'].array()\n",
    "Track_ind = data_file['ticlDumper/tracksters;1']['vertices_indexes'].array()\n",
    "GT_ind = data_file['ticlDumper/simtrackstersCP;1']['vertices_indexes'].array()\n",
    "GT_mult = data_file['ticlDumper/simtrackstersCP;1']['vertices_multiplicity'].array()\n",
    "energies = data_file['ticlDumper/clusters;1']['energy'].array()\n",
    "MT_ind = data_file['ticlDumper/trackstersMerged;1']['vertices_indexes'].array()\n",
    "ass = data_file['ticlDumper/associations;1']['tsCLUE3D_recoToSim_CP'].array()\n",
    "\n",
    "TrueEnergy = data_file['ticlDumper/simtrackstersCP;1']['regressed_energy'].array()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55d996ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueEnergy = data_file['ticlDumper/simtrackstersCP;1']['regressed_energy'].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9dcc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Calculate Scores and create DF for our model and TICL\n",
    "\n",
    "#4.1: Turn the cluster labels into our reconstructed tracksters\n",
    "\n",
    "recon_ind = []\n",
    "\n",
    "for event_idx, labels in enumerate(all_cluster_labels):\n",
    "\n",
    "    event_clusters = {} \n",
    "    \n",
    "    for cluster_idx, cluster_label in enumerate(labels):\n",
    "        if cluster_label not in event_clusters:\n",
    "            event_clusters[cluster_label] = []\n",
    "        event_clusters[cluster_label].extend(Track_ind[event_idx][cluster_idx])\n",
    "    \n",
    "    recon_ind.append([event_clusters[label] for label in sorted(event_clusters.keys())])\n",
    "\n",
    "#4.2 Make DF from our model and CERN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59dca8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 5, 10, 15, 16, 29, 37, 49, 56, 71, 79, 83, 96, 103, 114, 121, 129, 133, 144, 147, 152, 153, 155, 157]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cee95d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "def filter_repeated_indexes(GT_ind, GT_mult):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "       - GT_ind: an awkward array (or list of lists) of indexes for one event.\n",
    "       - GT_mult: an awkward array (or list of lists) of multiplicity values (same shape as GT_ind).\n",
    "    \n",
    "    For any index that appears in more than one sub-array, keep only the occurrence with the\n",
    "    smallest multiplicity, and set that multiplicity to 1.0. All other occurrences are removed.\n",
    "    \n",
    "    Returns:\n",
    "       new_GT_ind, new_GT_mult  \n",
    "         Both are returned as <class 'awkward.highlevel.Array'>.\n",
    "    \"\"\"\n",
    "    # 1. Record all occurrences of each index.\n",
    "    occurrences = {}\n",
    "    for sub_i, (sub_ind, sub_mult) in enumerate(zip(GT_ind, GT_mult)):\n",
    "        for pos, (val, mult) in enumerate(zip(sub_ind, sub_mult)):\n",
    "            occurrences.setdefault(val, []).append((sub_i, pos, mult))\n",
    "    \n",
    "    # 2. Mark occurrences to remove and those to update.\n",
    "    removals = set()\n",
    "    update_to_one = set()\n",
    "    \n",
    "    for index_val, occ_list in occurrences.items():\n",
    "        if len(occ_list) > 1:\n",
    "            occ_list_sorted = sorted(occ_list, key=lambda x: x[2])  # Sort by multiplicity\n",
    "            kept_occ = occ_list_sorted[0]  # Keep lowest multiplicity\n",
    "            update_to_one.add((kept_occ[0], kept_occ[1]))\n",
    "            for occ in occ_list_sorted[1:]:\n",
    "                removals.add((occ[0], occ[1]))\n",
    "    \n",
    "    # 3. Reconstruct new GT_ind and GT_mult by filtering out the removals.\n",
    "    new_GT_ind = []\n",
    "    new_GT_mult = []\n",
    "    for sub_i, (sub_ind, sub_mult) in enumerate(zip(GT_ind, GT_mult)):\n",
    "        new_sub_ind = []\n",
    "        new_sub_mult = []\n",
    "        for pos, (val, mult) in enumerate(zip(sub_ind, sub_mult)):\n",
    "            if (sub_i, pos) in removals:\n",
    "                continue\n",
    "            new_sub_ind.append(val)\n",
    "            new_sub_mult.append(1.0 if (sub_i, pos) in update_to_one else mult)\n",
    "        new_GT_ind.append(new_sub_ind)\n",
    "        new_GT_mult.append(new_sub_mult)\n",
    "    \n",
    "    # Convert lists to awkward arrays\n",
    "    return ak.Array(new_GT_ind), ak.Array(new_GT_mult)\n",
    "\n",
    "def filter_repeated_indexes_for_events(all_GT_ind, all_GT_mult):\n",
    "    \"\"\"\n",
    "    Given a list of events, each with its GT_ind and GT_mult (lists of sub-arrays),\n",
    "    apply filter_repeated_indexes to each event.\n",
    "    \n",
    "    Args:\n",
    "        all_GT_ind: List of events. Each event is an awkward array (or list of sub-arrays) of indexes.\n",
    "        all_GT_mult: List of events. Each event is an awkward array (or list of sub-arrays) of multiplicity values.\n",
    "    \n",
    "    Returns:\n",
    "        new_all_GT_ind, new_all_GT_mult: Awkward arrays (one per event) of filtered GT_ind and GT_mult.\n",
    "    \"\"\"\n",
    "    new_all_GT_ind = []\n",
    "    new_all_GT_mult = []\n",
    "    \n",
    "    # Loop over each event\n",
    "    for event_ind, event_mult in zip(all_GT_ind, all_GT_mult):\n",
    "        new_event_ind, new_event_mult = filter_repeated_indexes(event_ind, event_mult)\n",
    "        new_all_GT_ind.append(new_event_ind)\n",
    "        new_all_GT_mult.append(new_event_mult)\n",
    "    \n",
    "    # Convert to awkward arrays\n",
    "    return ak.Array(new_all_GT_ind), ak.Array(new_all_GT_mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdd5ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_ind, GT_mult = filter_repeated_indexes_for_events(GT_ind, GT_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97e22c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Create new lists to store the filtered results\n",
    "# This makes sure GT_ind, MT_ind, Recon_ind have the same indices\n",
    "filtered_GT_ind = []\n",
    "filtered_GT_mult = []\n",
    "filtered_MT_ind = []\n",
    "\n",
    "\n",
    "for event_idx, track_indices in enumerate(Track_ind):\n",
    "    # Flatten the current event's track indices and convert to a set\n",
    "    track_flat = set(ak.flatten(track_indices).tolist())  # Ensure it contains only integers\n",
    "    \n",
    "    # Filter GT_ind and GT_mult for the current event, preserving structure\n",
    "    event_GT_ind = GT_ind[event_idx]\n",
    "    event_GT_mult = GT_mult[event_idx]\n",
    "    filtered_event_GT_ind = []\n",
    "    filtered_event_GT_mult = []\n",
    "    for sublist_ind, sublist_mult in zip(event_GT_ind, event_GT_mult):\n",
    "        filtered_sublist_ind = [idx for idx in sublist_ind if idx in track_flat]\n",
    "        filtered_sublist_mult = [mult for idx, mult in zip(sublist_ind, sublist_mult) if idx in track_flat]\n",
    "        filtered_event_GT_ind.append(filtered_sublist_ind)\n",
    "        filtered_event_GT_mult.append(filtered_sublist_mult)\n",
    "\n",
    "    # Filter MT_ind for the current event, preserving structure\n",
    "    event_MT_ind = MT_ind[event_idx]\n",
    "    filtered_event_MT_ind = []\n",
    "    for sublist in event_MT_ind:\n",
    "        filtered_sublist = [idx for idx in sublist if idx in track_flat]\n",
    "        filtered_event_MT_ind.append(filtered_sublist)\n",
    "\n",
    "    # Append filtered results\n",
    "    filtered_GT_ind.append(filtered_event_GT_ind)\n",
    "    filtered_GT_mult.append(filtered_event_GT_mult)\n",
    "    filtered_MT_ind.append(filtered_event_MT_ind)\n",
    "\n",
    "# Convert the filtered results back to awkward arrays\n",
    "GT_ind_filt = ak.Array(filtered_GT_ind)\n",
    "GT_mult_filt = ak.Array(filtered_GT_mult)\n",
    "MT_ind_filt = ak.Array(filtered_MT_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e01721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99996185302734\n"
     ]
    }
   ],
   "source": [
    "print(TrueEnergy[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "def calculate_all_event_scores(GT_ind, energies, recon_ind, RegressedEnergy, num_events = 100):\n",
    "    \"\"\"\n",
    "    Calculate sim-to-reco and reco-to-sim scores for all CaloParticle and ReconstructedTrackster combinations across all events.\n",
    "\n",
    "    Parameters:\n",
    "    - GT_ind: List of CaloParticle indices for all events.\n",
    "    - energies: List of energy arrays for all events.\n",
    "    - recon_ind: List of ReconstructedTrackster indices for all events.\n",
    "    - LC_x, LC_y, LC_z, LC_eta: Lists of x, y, z positions and eta values for all DetIds across events.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing scores and additional features for each CaloParticle-Trackster combination across all events.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store results\n",
    "    all_results = []\n",
    "\n",
    "    # Loop over all events with a progress bar\n",
    "    for event_index in tqdm(range(num_events)):\n",
    "        caloparticles = GT_ind[event_index]  # Indices for all CaloParticles in the event\n",
    "        tracksters = recon_ind[event_index]  # Indices for all ReconstructedTracksters in the event\n",
    "        event_energies = energies[event_index]  # Energies for this event\n",
    "        TrueEnergy = RegressedEnergy[event_index][0]\n",
    "        trackster_det_id_sets = [set(trackster) for trackster in tracksters]\n",
    "\n",
    "        # Loop over all CaloParticles\n",
    "        for calo_idx, caloparticle in enumerate(caloparticles):\n",
    "\n",
    "            calo_det_ids = set(calo_id for calo_id in caloparticle)\n",
    "            # Loop over all Tracksters\n",
    "            for trackster_idx, trackster in enumerate(tracksters):\n",
    "                # Calculate sim-to-reco score\n",
    "                trackster_det_ids = trackster_det_id_sets[trackster_idx]\n",
    "                shared_det_ids = calo_det_ids.intersection(trackster_det_ids)\n",
    "                \n",
    "                # Calculate shared_energy by summing energies of shared det_ids\n",
    "                shared_energy = np.sum(event_energies[list(shared_det_ids)]) if shared_det_ids else 0.0\n",
    "                \n",
    "\n",
    "\n",
    "                cp_energy = TrueEnergy\n",
    "                \n",
    "                trackster_energy = np.sum([event_energies[det_id] for det_id in trackster])\n",
    "\n",
    "                # Calculate energy difference ratio\n",
    "                energy_diff_ratio = (trackster_energy / cp_energy if cp_energy != 0 else None)\n",
    "\n",
    "                # Append results\n",
    "                all_results.append({\n",
    "                    \"event_index\": event_index,\n",
    "                    \"cp_id\": calo_idx,\n",
    "                    \"trackster_id\": trackster_idx,\n",
    "                    \"cp_energy\": cp_energy,\n",
    "                    \"trackster_energy\": trackster_energy,\n",
    "                    \"energy_ratio\": energy_diff_ratio,\n",
    "                    \"shared_energy\": shared_energy  # New column\n",
    "                })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
