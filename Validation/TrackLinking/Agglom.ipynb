{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading tracksters data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vols/cms/mm1221/Data/100k/5pi/test/raw/test.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                     | 0/1 [00:16<?, ?it/s]\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 500 events!\n",
      "### Loading tracksters data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vols/cms/mm1221/Data/100k/5e/test/raw/test.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                     | 0/1 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 500 events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9763\n"
     ]
    }
   ],
   "source": [
    "#0: imports\n",
    "\n",
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from imports.data import CCV1\n",
    "from torch_geometric.data import DataLoader \n",
    "from imports.models import Net_SEC, Net_GAT, Net_Trans\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import time\n",
    "from imports.Agglomerative import Aggloremative\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "Ppath = '/vols/cms/mm1221/Data/100k/5pi/test/'\n",
    "Epath = '/vols/cms/mm1221/Data/100k/5e/test/'\n",
    "# Load test data\n",
    "data_P = CCV1(Ppath, max_events=500)\n",
    "P_loader = DataLoader(data_P, batch_size=1, shuffle=False, follow_batch=['x'])\n",
    "\n",
    "data_E = CCV1(Epath, max_events=500)\n",
    "E_loader = DataLoader(data_E, batch_size=1, shuffle=False, follow_batch=['x'])\n",
    "\n",
    "\n",
    "import uproot\n",
    "\n",
    "# Define the file paths\n",
    "data_Ep_path = '/vols/cms/mm1221/Data/100k/5e/test/raw/test.root'  # electron file\n",
    "data_Pp_path = '/vols/cms/mm1221/Data/100k/5pi/test/raw/test.root'  # pion file\n",
    "\n",
    "# Open the ROOT files using uproot\n",
    "file_Ep = uproot.open(data_Ep_path)\n",
    "file_Pp = uproot.open(data_Pp_path)\n",
    "\n",
    "# Load the branches for electrons (data_Ep)\n",
    "GT_ind_Ep   = file_Ep['simtrackstersCP']['vertices_indexes'].array()\n",
    "GT_mult_Ep  = file_Ep['simtrackstersCP']['vertices_multiplicity'].array()\n",
    "energies_Ep = file_Ep['clusters']['energy'].array()\n",
    "LC_x_Ep     = file_Ep['clusters']['position_x'].array()\n",
    "Track_ind_Ep = file_Ep['tracksters']['vertices_indexes'].array()\n",
    "bc_x_Ep = file_Ep['tracksters']['barycenter_x'].array()\n",
    "\n",
    "# Load the branches for pions (data_Pp)\n",
    "GT_ind_Pp   = file_Pp['simtrackstersCP']['vertices_indexes'].array()\n",
    "GT_mult_Pp  = file_Pp['simtrackstersCP']['vertices_multiplicity'].array()\n",
    "energies_Pp = file_Pp['clusters']['energy'].array()\n",
    "Track_ind_Pp = file_Pp['tracksters']['vertices_indexes'].array()\n",
    "LC_x_Pp     = file_Pp['clusters']['position_x'].array()\n",
    "bc_x_Pp = file_Pp['tracksters']['barycenter_x'].array()\n",
    "\n",
    "# Create a skim mask to filter out events with 0 calorimeter particles (for electrons)\n",
    "skim_mask_Ep = [len(e) >= 1 for e in bc_x_Ep]\n",
    "\n",
    "# Apply the skim mask to filter the electron arrays\n",
    "GT_ind_Ep   = GT_ind_Ep[skim_mask_Ep]\n",
    "GT_mult_Ep  = GT_mult_Ep[skim_mask_Ep]\n",
    "energies_Ep = energies_Ep[skim_mask_Ep]\n",
    "Track_ind_Ep = Track_ind_Ep[skim_mask_Ep]\n",
    "\n",
    "# Create a skim mask for pions\n",
    "skim_mask = []\n",
    "for e in bc_x_Pp:\n",
    "    if len(e) == 0:\n",
    "        skim_mask.append(False)\n",
    "    else:\n",
    "        skim_mask.append(True)\n",
    "\n",
    "# Apply the skim mask to filter the pion arrays\n",
    "GT_ind_Pp   = GT_ind_Pp[skim_mask]\n",
    "GT_mult_Pp  = GT_mult_Pp[skim_mask]\n",
    "energies_Pp = energies_Pp[skim_mask]\n",
    "Track_ind_Pp = Track_ind_Pp[skim_mask]\n",
    "\n",
    "print(len(Track_ind_Pp))\n",
    "\n",
    "import awkward as ak\n",
    "\n",
    "# ----- For pions -----\n",
    "\n",
    "\n",
    "# Initialize lists to store filtered results for pions\n",
    "filtered_GT_ind_P = []\n",
    "filtered_GT_mult_P = []\n",
    "\n",
    "# Loop over events for pions\n",
    "for event_idx, track_indices in enumerate(Track_ind_Pp):\n",
    "    # Flatten the current event's track indices and convert to a set\n",
    "    track_flat = set(ak.flatten(track_indices).tolist())\n",
    "    \n",
    "    # Get the current event's GT arrays\n",
    "    event_GT_ind = GT_ind_Pp[event_idx]\n",
    "    event_GT_mult = GT_mult_Pp[event_idx]\n",
    "    \n",
    "    # Initialize lists for the filtered sublists in the current event\n",
    "    filtered_event_GT_ind = []\n",
    "    filtered_event_GT_mult = []\n",
    "    \n",
    "    # Loop over the sublists and filter using the track_flat set\n",
    "    for sublist_ind, sublist_mult in zip(event_GT_ind, event_GT_mult):\n",
    "        filtered_sublist_ind = [idx for idx in sublist_ind if idx in track_flat]\n",
    "        filtered_sublist_mult = [mult for idx, mult in zip(sublist_ind, sublist_mult) if idx in track_flat]\n",
    "        filtered_event_GT_ind.append(filtered_sublist_ind)\n",
    "        filtered_event_GT_mult.append(filtered_sublist_mult)\n",
    "    \n",
    "    # Append the filtered event arrays to the output lists for pions\n",
    "    filtered_GT_ind_P.append(filtered_event_GT_ind)\n",
    "    filtered_GT_mult_P.append(filtered_event_GT_mult)\n",
    "\n",
    "# Convert the filtered results back into awkward Arrays for pions\n",
    "GT_ind_filt_P = ak.Array(filtered_GT_ind_P)\n",
    "GT_mult_filt_P = ak.Array(filtered_GT_mult_P)\n",
    "\n",
    "# ----- For electrons -----\n",
    "\n",
    "# Initialize lists to store filtered results for electrons\n",
    "filtered_GT_ind_E = []\n",
    "filtered_GT_mult_E = []\n",
    "\n",
    "# Loop over events for electrons\n",
    "for event_idx, track_indices in enumerate(Track_ind_Ep):\n",
    "\n",
    "    # Flatten the current event's track indices and convert to a set\n",
    "    track_flat = set(ak.flatten(track_indices).tolist())\n",
    "    \n",
    "    # Get the current event's GT arrays\n",
    "    event_GT_ind = GT_ind_Ep[event_idx]\n",
    "    event_GT_mult = GT_mult_Ep[event_idx]\n",
    "    \n",
    "    # Initialize lists for the filtered sublists in the current event\n",
    "    filtered_event_GT_ind = []\n",
    "    filtered_event_GT_mult = []\n",
    "    \n",
    "    # Loop over the sublists and filter using the track_flat set\n",
    "    for sublist_ind, sublist_mult in zip(event_GT_ind, event_GT_mult):\n",
    "        filtered_sublist_ind = [idx for idx in sublist_ind if idx in track_flat]\n",
    "        filtered_sublist_mult = [mult for idx, mult in zip(sublist_ind, sublist_mult) if idx in track_flat]\n",
    "        filtered_event_GT_ind.append(filtered_sublist_ind)\n",
    "        filtered_event_GT_mult.append(filtered_sublist_mult)\n",
    "    \n",
    "    # Append the filtered event arrays to the output lists for electrons\n",
    "    filtered_GT_ind_E.append(filtered_event_GT_ind)\n",
    "    filtered_GT_mult_E.append(filtered_event_GT_mult)\n",
    "\n",
    "# Convert the filtered results back into awkward Arrays for electrons\n",
    "GT_ind_filt_E = ak.Array(filtered_GT_ind_E)\n",
    "GT_mult_filt_E = ak.Array(filtered_GT_mult_E)\n",
    "\n",
    "model = Net_GAT(128,3, dropout=0.3, contrastive_dim=512, heads=16)\n",
    "checkpoint= torch.load('/vols/cms/mm1221/hgcal/Mixed/Track/NegativeMining/runs/GATNEW/hd128nl3cd512k64h16/epoch-100.pt',  map_location=torch.device('cpu'))\n",
    "#checkpoint= torch.load('/vols/cms/er421/hgcal/code/code/Mixed/LC/Full/results/hd128nl3cd16k64/epoch-100.pt',  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model'])  \n",
    "model.eval()  \n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_metrics(df, model_name):\n",
    "    # ----- Efficiency Calculation -----\n",
    "    # Step 1: Filter out rows where 'cp_id' is NaN\n",
    "    cp_valid = df.dropna(subset=['cp_id']).copy()\n",
    "\n",
    "    # Step 2: Group by 'event_index' and 'cp_id' to proess each CaloParticle individually\n",
    "    cp_grouped = cp_valid.groupby(['event_index', 'cp_id'])\n",
    "\n",
    "    # Step 3: For each CaloParticle, check if any 'shared_energy' >= 50% of 'cp_raw_energy'\n",
    "    def is_cp_associated(group):\n",
    "        cp_raw_energy = group['cp_energy'].iloc[0]  # Assuming 'cp_raw_energy' is consistent within the group\n",
    "        threshold = 0.8 * cp_raw_energy\n",
    "        return (group['shared_energy'] >= threshold).any()\n",
    "\n",
    "    # Apply the association function to each group\n",
    "    cp_associated = cp_grouped.apply(is_cp_associated)\n",
    "\n",
    "    # Step 4: Calculate the number of associated CaloParticles and total CaloParticles\n",
    "    num_associated_cp = cp_associated.sum()\n",
    "    total_cp = cp_associated.count()\n",
    "    efficiency = num_associated_cp / total_cp if total_cp > 0 else 0\n",
    "\n",
    "    # ----- Purity Calculation -----\n",
    "    tst_valid = df.dropna(subset=['trackster_id']).copy()\n",
    "    tst_grouped = tst_valid.groupby(['event_index', 'trackster_id'])\n",
    "    tst_associated = tst_grouped['reco_to_sim_score'].min() < 0.2\n",
    "    num_associated_tst = tst_associated.sum()\n",
    "    total_tst = tst_associated.count()\n",
    "    purity = num_associated_tst / total_tst if total_tst > 0 else 0\n",
    "    \n",
    "    # ----- Ratio between num of tracksters to caloparticles Calculation -----\n",
    "    num_tracksters_ratio = total_tst / total_cp if total_cp > 0 else 0\n",
    "    \n",
    "    # Print results for the model\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Efficiency: {efficiency:.4f} ({num_associated_cp} associated CPs out of {total_cp} total CPs)\")\n",
    "    print(f\"FR: {1 - purity:.4f} ({num_associated_tst} associated Tracksters out of {total_tst} total Tracksters)\")\n",
    "    print(f\"Num tracksters ratio: {num_tracksters_ratio}\")\n",
    "\n",
    "    return {\n",
    "        'efficiency': efficiency,\n",
    "        'purity': purity,\n",
    "        'Num_tracksters_ratio': num_tracksters_ratio,\n",
    "    }\n",
    "\n",
    "from tqdm import tqdm\n",
    "def calculate_reco_to_sim_score_and_sharedE(ReconstructedTrackster, energies_indices, CaloParticle, calo_mult):\n",
    "    \"\"\"\n",
    "    Calculate the reco-to-sim score for a given ReconstructedTrackster and CaloParticle.\n",
    "\n",
    "    Parameters:\n",
    "    - ReconstructedTrackster: array of DetIds in the ReconstructedTrackster.\n",
    "    - energies_indices: array of energies associated with all DetIds (indexed by DetId).\n",
    "    - CaloParticle: array of DetIds in the CaloParticle.\n",
    "\n",
    "    Returns:\n",
    "    - reco_to_sim_score: the calculated reco-to-sim score.\n",
    "    \"\"\"\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "    sharedEnergy = 0.0\n",
    "\n",
    "    # Iterate over all DetIds in the ReconstructedTrackster\n",
    "    for i, det_id in enumerate(ReconstructedTrackster):\n",
    "        energy_k = energies_indices[det_id]  # Energy for the current DetId in the Trackster\n",
    "        \n",
    "        # Fraction of energy in the Trackster (fr_k^TST)\n",
    "        fr_tst_k = 1 \n",
    "\n",
    "        #Fraction of energy in the caloparticle\n",
    "        if det_id in CaloParticle:\n",
    "            index = np.where(CaloParticle == det_id)[0][0]\n",
    "            fr_sc_k = 1 / calo_mult[index]\n",
    "            \n",
    "        else:\n",
    "            fr_sc_k = 0 # binary function also for CaloParticle\n",
    "            \n",
    "        # Update numerator using the min function\n",
    "        numerator += min(\n",
    "            (fr_tst_k - fr_sc_k) ** 2,  # First term in the min function\n",
    "            fr_tst_k ** 2               # Second term in the min function\n",
    "        ) * (energy_k ** 2)\n",
    "\n",
    "        # Update denominator\n",
    "        denominator += (fr_tst_k ** 2) * (energy_k ** 2)\n",
    "        \n",
    "        #shared_energy calculation\n",
    "        recosharedEnergy = energy_k * fr_tst_k\n",
    "        simsharedEnergy = energy_k * fr_sc_k\n",
    "        sharedEnergy += min(simsharedEnergy,recosharedEnergy)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Calculate score\n",
    "    reco_to_sim_score = numerator / denominator if denominator != 0 else 1.0\n",
    "    return reco_to_sim_score, sharedEnergy\n",
    "\n",
    "\n",
    "def calculate_all_event_scores(GT_ind, GT_mult, energies, recon_ind,  num_events = 100):\n",
    "    \"\"\"\n",
    "    Calculate sim-to-reco and reco-to-sim scores for all CaloParticle and ReconstructedTrackster combinations across all events.\n",
    "\n",
    "    Parameters:\n",
    "    - GT_ind: List of CaloParticle indices for all events.\n",
    "    - energies: List of energy arrays for all events.\n",
    "    - recon_ind: List of ReconstructedTrackster indices for all events.\n",
    "    - LC_x, LC_y, LC_z, LC_eta: Lists of x, y, z positions and eta values for all DetIds across events.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing scores and additional features for each CaloParticle-Trackster combination across all events.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store results\n",
    "    all_results = []\n",
    "\n",
    "    # Loop over all events with a progress bar\n",
    "    for event_index in tqdm(range(num_events)):\n",
    "        caloparticles = GT_ind[event_index]  # Indices for all CaloParticles in the event\n",
    "        tracksters = recon_ind[event_index]  # Indices for all ReconstructedTracksters in the event\n",
    "        event_energies = energies[event_index]  # Energies for this event\n",
    "        event_GT_mult = GT_mult[event_index]\n",
    "        \n",
    "        # Loop over all CaloParticles\n",
    "        for calo_idx, caloparticle in enumerate(caloparticles):\n",
    "            calo_mult = event_GT_mult[calo_idx]\n",
    "            cp_raw_energy_lc = event_energies[caloparticle] / calo_mult\n",
    "            cp_raw_energy = np.sum(cp_raw_energy_lc)\n",
    "\n",
    "            \n",
    "            for trackster_idx, trackster in enumerate(tracksters):\n",
    "\n",
    "                \n",
    "                # Calculate reco-to-sim score\n",
    "                reco_to_sim_score, shared_energy = calculate_reco_to_sim_score_and_sharedE(trackster, event_energies, caloparticle,calo_mult)\n",
    "                # Calculate trackster energy\n",
    "\n",
    "                # Append results\n",
    "                all_results.append({\n",
    "                    \"event_index\": event_index,\n",
    "                    \"cp_id\": calo_idx,\n",
    "                    \"trackster_id\": trackster_idx,\n",
    "                    \"reco_to_sim_score\": reco_to_sim_score,\n",
    "                    \"cp_energy\": cp_raw_energy,\n",
    "                    \"shared_energy\": shared_energy,\n",
    "                })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return df\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Define your threshold scan with more data points:\n",
    "#    - From 0 to 0.4: every 0.005\n",
    "#    - From 0.4 to 1: every 0.02\n",
    "# ---------------------------------------------------------\n",
    "first_segment = np.arange(0, 0.3, 0.002)\n",
    "second_segment = np.arange(0.3, 1.01, 0.01)  # 1.02 to ensure inclusion of 1.0\n",
    "threshold_values = np.concatenate((first_segment, second_segment))\n",
    "\n",
    "# Optionally, you can save these DataFrames to CSV files:\n",
    "\n",
    "\n",
    "all_predictions_P = []\n",
    "for i, data in enumerate(P_loader):  # P_loader => DataLoader for pion data\n",
    "    edge_index = knn_graph(data.x[:, :3], k=64, batch=data.x_batch)\n",
    "    pred = model(data.x,edge_index, data.x_batch)\n",
    "    all_predictions_P.append(pred[0].detach().cpu().numpy())\n",
    "\n",
    "efficiencies_P, fakerates_P, ratio_P = [], [], []\n",
    "# ---------------------------------------------------------\n",
    "# 5) Loop over thresholds and compute metrics for pions\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd29b51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pions] Threshold = 0.000\n",
      "9763\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in ListOffsetArray64 attempting to get 0, index out of range\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/libawkward/array/ListOffsetArray.cpp#L682)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_567146/3416617330.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcluster_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mevent_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mevent_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrack_ind_Pp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrecon_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_clusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/awkward/highlevel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \"\"\"\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_tracers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_behavior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jaxtracers_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in ListOffsetArray64 attempting to get 0, index out of range\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/libawkward/array/ListOffsetArray.cpp#L682)"
     ]
    }
   ],
   "source": [
    "for t in threshold_values:\n",
    "    print(f\"\\n[Pions] Threshold = {t:.3f}\")\n",
    "    \n",
    "    # --- 4.1 Cluster using your Aggloremative function (or other) ---\n",
    "    all_cluster_labels = Aggloremative(all_predictions_P, threshold=t)\n",
    "    print(len(all_cluster_labels))\n",
    "    # --- 4.2 Reconstruct tracksters ---\n",
    "    # Build \"recon_ind_E\" by grouping cluster indices for each event\n",
    "    recon_ind = []\n",
    "\n",
    "    for event_idx, labels in enumerate(all_cluster_labels):\n",
    "\n",
    "        event_clusters = {} \n",
    "\n",
    "        for cluster_idx, cluster_label in enumerate(labels):\n",
    "            if cluster_label not in event_clusters:\n",
    "                event_clusters[cluster_label] = []\n",
    "            event_clusters[cluster_label].extend(Track_ind_Pp[event_idx][cluster_idx])\n",
    "\n",
    "        recon_ind.append([event_clusters[label] for label in sorted(event_clusters.keys())])\n",
    "    \n",
    "\n",
    "    # --- 5.3 Calculate event scores ---\n",
    "    # Use your *filtered* GT arrays and energies for pions\n",
    "    df_CL_temp_P = calculate_all_event_scores(\n",
    "        GT_ind_filt_P, \n",
    "        GT_mult_filt_P, \n",
    "        energies_Pp, \n",
    "        recon_ind, \n",
    "        num_events=300  # using 50 events\n",
    "    )\n",
    "    \n",
    "    # --- 5.4 Compute metrics and store in lists ---\n",
    "    metrics_P = calculate_metrics(df_CL_temp_P, f\"Threshold {t:.3f}\")\n",
    "    efficiencies_P.append(metrics_P['efficiency'])\n",
    "    fakerates_P.append(1.0 - metrics_P['purity'])  \n",
    "    ratio_P.append(metrics_P['Num_tracksters_ratio'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6) Build separate DataFrames for electrons and pions\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "df_pions = pd.DataFrame({\n",
    "    'threshold': threshold_values,\n",
    "    'efficiency': efficiencies_P,\n",
    "    'fake_rate': fakerates_P,\n",
    "    'num_tracksters_ratio': ratio_P,\n",
    "})\n",
    "\n",
    "df_pions.to_csv(\"pion_GAT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca7e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9837\n"
     ]
    }
   ],
   "source": [
    "print(len(Track_ind_Pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d148af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 102, 151, 180, 203, 234, 235, 266, ... 1181, 1193, 1216, 1217], [1194, 1215]]\n"
     ]
    }
   ],
   "source": [
    "print(Track_ind_Pp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8712a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
