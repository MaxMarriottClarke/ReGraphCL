{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5376aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: imports\n",
    "\n",
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from imports.data import CCV1\n",
    "from torch_geometric.data import DataLoader \n",
    "from imports.models import Net_SEC, Net_GAT, Net_Trans\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import time\n",
    "from imports.Agglomerative import Aggloremative\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20044878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading tracksters data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vols/cms/mm1221/Data/mix/test/raw/test.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 500 events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "testpath = '/vols/cms/mm1221/Data/mix/test/'\n",
    "# Load test data\n",
    "data_test = CCV1(testpath, max_events=500)\n",
    "test_loader = DataLoader(data_test, batch_size=1, shuffle=False, follow_batch=['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f325a9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_SEC(\n",
       "  (lc_encode): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0-2): 3 x CustomStaticEdgeConv(\n",
       "      (nn_module): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ELU(alpha=1.0)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net_SEC(256,3, dropout=0.3, contrastive_dim=512)\n",
    "checkpoint= torch.load('/vols/cms/mm1221/hgcal/Mixed/Track/NegativeMining/runs/SECNEW/hd256nl3cd512k64/epoch-100.pt',  map_location=torch.device('cpu'))\n",
    "#checkpoint= torch.load('/vols/cms/er421/hgcal/code/code/Mixed/LC/Full/results/hd128nl3cd16k64/epoch-100.pt',  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model'])  \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0232b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average inference time: 0.015218088397155964\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances  # for cosine distance calculation\n",
    "\n",
    "all_predictions = []  \n",
    "start_time = time.time()\n",
    "\n",
    "# Get predictions for each event\n",
    "for i, data in enumerate(test_loader):\n",
    "    if i > 300:\n",
    "        break\n",
    "    edge_index = knn_graph(data.x[:, :3], k=64, batch=data.x_batch)\n",
    "\n",
    "\n",
    "    predictions = model(data.x, edge_index, data.x_batch)\n",
    "    all_predictions.append(predictions[0].detach().cpu().numpy())  \n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "# 3.2: Cluster using threshold found in Script A\n",
    "all_cluster_labels = Aggloremative(all_predictions, threshold=0.165)\n",
    "#all_cluster_labels = affinity_propagation_clustering(all_predictions, damping=0.7)\n",
    "\"\"\"\n",
    "all_cluster_labels = mean_shift_clustering(\n",
    "    all_predictions,\n",
    "    bandwidth=None,    # Or a numeric value if you already have a good estimate\n",
    "    quantile=0.2,      # Tweak quantile to control bandwidth estimation\n",
    "    n_samples=500      # You can limit the sample size if data is large\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# 3.3: Calculate average inference time\n",
    "time_diff = end_time - start_time\n",
    "inference_time = time_diff / len(all_cluster_labels)\n",
    "print(\"average inference time:\", inference_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0415b6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing events: 100%|██████████████████████| 100/100 [00:03<00:00, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Positive Edge Cosine Similarity: 0.8901\n",
      "Mean Negative Edge Cosine Similarity: 0.4884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Helper: compute cosine similarities for a list of edges\n",
    "def compute_cosine_similarities(embeddings, edge_indices, skip_self=True):\n",
    "    \"\"\"\n",
    "    embeddings: NumPy array of shape [N, D]\n",
    "    edge_indices: list of [src, tgt]\n",
    "    skip_self: whether to skip edges where src == tgt\n",
    "    \"\"\"\n",
    "    sims = []\n",
    "    for edge in edge_indices:\n",
    "        src, tgt = edge\n",
    "        if skip_self and src == tgt:\n",
    "            continue\n",
    "        # Cosine similarity for these two rows\n",
    "        sim = cosine_similarity(embeddings[[src, tgt], :])[0, 1]\n",
    "        sims.append(sim)\n",
    "    return np.array(sims)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Build pos & neg edges from data_test[i].assoc\n",
    "def build_edges_from_assoc(data_item):\n",
    "    \"\"\"\n",
    "    data_item.assoc: array of length N specifying a group ID for each node in the event.\n",
    "    We assume data_item.assoc[n] is an integer: the group ID of node n.\n",
    "    \"\"\"\n",
    "    group_ids = data_item.assoc\n",
    "    N = len(group_ids)\n",
    "\n",
    "    pos_edges = []\n",
    "    neg_edges = []\n",
    "\n",
    "    # Generate all unique pairs i < j\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            if group_ids[i] == group_ids[j]:\n",
    "                pos_edges.append([i, j])\n",
    "            else:\n",
    "                neg_edges.append([i, j])\n",
    "\n",
    "    return pos_edges, neg_edges\n",
    "\n",
    "# ---------------------------------------------\n",
    "num_events = 100  # Example: process the first 10 events\n",
    "all_pos_sims = []\n",
    "all_neg_sims = []\n",
    "\n",
    "for i in tqdm(range(num_events), desc=\"Processing events\"):\n",
    "    # 'all_predictions[i]' is shape [N, embedding_dim],\n",
    "    # matching the length of data_test[i].assoc\n",
    "    pred_tensor = torch.tensor(all_predictions[i], dtype=torch.float32)\n",
    "    # Normalize embeddings\n",
    "    pred_norm = F.normalize(pred_tensor, p=2, dim=1)\n",
    "    embeddings = pred_norm.cpu().numpy()\n",
    "\n",
    "    # Build positive & negative edges based on group IDs\n",
    "    pos_edge_indices, neg_edge_indices = build_edges_from_assoc(data_test[i])\n",
    "\n",
    "    # Compute similarities\n",
    "    pos_sims = compute_cosine_similarities(embeddings, pos_edge_indices, skip_self=True)\n",
    "    neg_sims = compute_cosine_similarities(embeddings, neg_edge_indices, skip_self=True)\n",
    "\n",
    "    # Accumulate for global stats\n",
    "    all_pos_sims.extend(pos_sims.tolist())\n",
    "    all_neg_sims.extend(neg_sims.tolist())\n",
    "\n",
    "all_pos_sims_no = np.array(all_pos_sims)\n",
    "all_neg_sims_no = np.array(all_neg_sims)\n",
    "\n",
    "mean_pos_sim = np.mean(all_pos_sims)\n",
    "mean_neg_sim = np.mean(all_neg_sims)\n",
    "\n",
    "print(f\"Mean Positive Edge Cosine Similarity: {mean_pos_sim:.4f}\")\n",
    "print(f\"Mean Negative Edge Cosine Similarity: {mean_neg_sim:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ed814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose we already have these arrays:\n",
    "# all_pos_sims, all_neg_sims (for NTXENT)\n",
    "# all_pos_sims_HN, all_neg_sims_HN (for HNNTXENT)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Left subplot: NTXENT\n",
    "axs[0].hist(all_pos_sims_no, bins=50, histtype=\"step\", linewidth=2, label=\"NTXENT Positive\")\n",
    "axs[0].hist(all_neg_sims_no, bins=50, histtype=\"step\", linewidth=2, label=\"NTXENT Negative\")\n",
    "\n",
    "axs[0].set_xlim(-1, 1)  # range of cosine similarity\n",
    "axs[0].set_xlabel(\"Cosine Similarity\", fontsize=14)\n",
    "axs[0].set_ylabel(\"Frequency\", fontsize=14)\n",
    "axs[0].set_title(\"NTXENT Distribution\", fontsize=16)\n",
    "axs[0].legend()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Right subplot: HNNTXENT\n",
    "axs[1].hist(all_pos_sims_hard, bins=50, histtype=\"step\", linewidth=2, label=\"HN-NTXENT Positive\")\n",
    "axs[1].hist(all_neg_sims_hard, bins=50, histtype=\"step\", linewidth=2, label=\"HN-NTXENT Negative\")\n",
    "\n",
    "axs[1].set_xlim(-1, 1)  # range of cosine similarity\n",
    "axs[1].set_xlabel(\"Cosine Similarity\", fontsize=14)\n",
    "axs[1].set_ylabel(\"Frequency\", fontsize=14)\n",
    "axs[1].set_title(\"HN-NTXENT Distribution\", fontsize=16)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"CosineTL.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c46d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
