{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745ab08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading tracksters data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vols/cms/mm1221/Data/le2pi/raw/step3_NTUPLE.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.24s/it]\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average inference time: 0.010399294219645876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 11321/11321 [00:51<00:00, 221.63it/s]\n",
      "100%|████████████████████████████████████| 11321/11321 [00:55<00:00, 204.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#0: imports\n",
    "\n",
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from imports.data_resp import CCV1\n",
    "from torch_geometric.data import DataLoader \n",
    "from imports.models import Net_SEC, Net_GAT, Net_Trans\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import time\n",
    "from imports.Agglomerative import Aggloremative\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "model = Net_Trans(128,3, dropout=0.3, contrastive_dim=64, num_heads=16)\n",
    "checkpoint= torch.load('/vols/cms/mm1221/hgcal/Mixed/Track/NegativeMining/runs/TransNew/hd128nl3cd64k90h16/epoch-94.pt',  map_location=torch.device('cpu'))\n",
    "#checkpoint= torch.load('/vols/cms/er421/hgcal/code/code/Mixed/LC/Full/results/hd128nl3cd16k64/epoch-100.pt',  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model'])  \n",
    "model.eval()\n",
    "\n",
    "testpath = '/vols/cms/mm1221/Data/le2pi/'\n",
    "# Load test data\n",
    "data_test = CCV1(testpath, max_events=20000)\n",
    "test_loader = DataLoader(data_test, batch_size=1, shuffle=False, follow_batch=['x'])\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances  # for cosine distance calculation\n",
    "\n",
    "all_predictions = []  \n",
    "start_time = time.time()\n",
    "\n",
    "# Get predictions for each event\n",
    "for i, data in enumerate(test_loader):\n",
    "    edge_index = knn_graph(data.x[:, :3], k=80, batch=data.x_batch)\n",
    "    predictions = model(data.x, edge_index, data.x_batch)\n",
    "    all_predictions.append(predictions[0].detach().cpu().numpy())  \n",
    "\n",
    "\n",
    "# 3.2: Cluster using threshold found in Script A\n",
    "all_cluster_labels = Aggloremative(all_predictions, threshold=0.17)\n",
    "#all_cluster_labels = affinity_propagation_clustering(all_predictions, damping=0.7)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# 3.3: Calculate average inference time\n",
    "time_diff = end_time - start_time\n",
    "inference_time = time_diff / len(all_cluster_labels)\n",
    "print(\"average inference time:\", inference_time)\n",
    "\n",
    "#4: Calculate Scores and create DF for our model and TICL\n",
    "\n",
    "#4.1: Turn the cluster labels into our reconstructed tracksters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#4.2 Make DF from our model and CERN\n",
    "# Also load explicitely, used for analysis and plots\n",
    "data_path = '/vols/cms/mm1221/Data/le2pi/raw/step3_NTUPLE.root'\n",
    "data_file = uproot.open(data_path)\n",
    "\n",
    "ass = data_file['ticlDumper/associations;1']['tsCLUE3D_recoToSim_CP'].array()\n",
    "Track_ind = data_file['ticlDumper/tracksters;1']['vertices_indexes'].array()\n",
    "GT_ind = data_file['ticlDumper/simtrackstersCP;1']['vertices_indexes'].array()\n",
    "GT_mult = data_file['ticlDumper/simtrackstersCP;1']['vertices_multiplicity'].array()\n",
    "energies = data_file['ticlDumper/clusters;1']['energy'].array()\n",
    "MT_ind = data_file['ticlDumper/trackstersMerged;1']['vertices_indexes'].array()\n",
    "ass = data_file['ticlDumper/associations;1']['tsCLUE3D_recoToSim_CP'].array()\n",
    "LC_x = data_file['ticlDumper/clusters;1']['position_x'].array()\n",
    "\n",
    "TrueEnergy = data_file['ticlDumper/simtrackstersCP;1']['regressed_energy'].array()\n",
    "\n",
    "t_bx = data_file['ticlDumper/tracksters']['barycenter_x'].array()\n",
    "skim_mask = []\n",
    "for e in t_bx:\n",
    "    if 1 <= len(e):\n",
    "        skim_mask.append(True)\n",
    "    else:\n",
    "        skim_mask.append(False)\n",
    "        \n",
    "ass = ass[skim_mask]\n",
    "Track_ind = Track_ind[skim_mask]\n",
    "GT_ind = GT_ind[skim_mask]\n",
    "GT_mult = GT_mult[skim_mask]\n",
    "energies = energies[skim_mask]\n",
    "MT_ind = MT_ind[skim_mask]\n",
    "TrueEnergy = TrueEnergy[skim_mask]\n",
    "\n",
    "import awkward as ak\n",
    "\n",
    "def filter_repeated_indexes(GT_ind, GT_mult):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "       - GT_ind: an awkward array (or list of lists) of indexes for one event.\n",
    "       - GT_mult: an awkward array (or list of lists) of multiplicity values (same shape as GT_ind).\n",
    "    \n",
    "    For any index that appears in more than one sub-array, keep only the occurrence with the\n",
    "    smallest multiplicity, and set that multiplicity to 1.0. All other occurrences are removed.\n",
    "    \n",
    "    Returns:\n",
    "       new_GT_ind, new_GT_mult  \n",
    "         Both are returned as <class 'awkward.highlevel.Array'>.\n",
    "    \"\"\"\n",
    "    # 1. Record all occurrences of each index.\n",
    "    occurrences = {}\n",
    "    for sub_i, (sub_ind, sub_mult) in enumerate(zip(GT_ind, GT_mult)):\n",
    "        for pos, (val, mult) in enumerate(zip(sub_ind, sub_mult)):\n",
    "            occurrences.setdefault(val, []).append((sub_i, pos, mult))\n",
    "    \n",
    "    # 2. Mark occurrences to remove and those to update.\n",
    "    removals = set()\n",
    "    update_to_one = set()\n",
    "    \n",
    "    for index_val, occ_list in occurrences.items():\n",
    "        if len(occ_list) > 1:\n",
    "            occ_list_sorted = sorted(occ_list, key=lambda x: x[2])  # Sort by multiplicity\n",
    "            kept_occ = occ_list_sorted[0]  # Keep lowest multiplicity\n",
    "            update_to_one.add((kept_occ[0], kept_occ[1]))\n",
    "            for occ in occ_list_sorted[1:]:\n",
    "                removals.add((occ[0], occ[1]))\n",
    "    \n",
    "    # 3. Reconstruct new GT_ind and GT_mult by filtering out the removals.\n",
    "    new_GT_ind = []\n",
    "    new_GT_mult = []\n",
    "    for sub_i, (sub_ind, sub_mult) in enumerate(zip(GT_ind, GT_mult)):\n",
    "        new_sub_ind = []\n",
    "        new_sub_mult = []\n",
    "        for pos, (val, mult) in enumerate(zip(sub_ind, sub_mult)):\n",
    "            if (sub_i, pos) in removals:\n",
    "                continue\n",
    "            new_sub_ind.append(val)\n",
    "            new_sub_mult.append(1.0 if (sub_i, pos) in update_to_one else mult)\n",
    "        new_GT_ind.append(new_sub_ind)\n",
    "        new_GT_mult.append(new_sub_mult)\n",
    "    \n",
    "    # Convert lists to awkward arrays\n",
    "    return ak.Array(new_GT_ind), ak.Array(new_GT_mult)\n",
    "\n",
    "def filter_repeated_indexes_for_events(all_GT_ind, all_GT_mult):\n",
    "    \"\"\"\n",
    "    Given a list of events, each with its GT_ind and GT_mult (lists of sub-arrays),\n",
    "    apply filter_repeated_indexes to each event.\n",
    "    \n",
    "    Args:\n",
    "        all_GT_ind: List of events. Each event is an awkward array (or list of sub-arrays) of indexes.\n",
    "        all_GT_mult: List of events. Each event is an awkward array (or list of sub-arrays) of multiplicity values.\n",
    "    \n",
    "    Returns:\n",
    "        new_all_GT_ind, new_all_GT_mult: Awkward arrays (one per event) of filtered GT_ind and GT_mult.\n",
    "    \"\"\"\n",
    "    new_all_GT_ind = []\n",
    "    new_all_GT_mult = []\n",
    "    \n",
    "    # Loop over each event\n",
    "    for event_ind, event_mult in zip(all_GT_ind, all_GT_mult):\n",
    "        new_event_ind, new_event_mult = filter_repeated_indexes(event_ind, event_mult)\n",
    "        new_all_GT_ind.append(new_event_ind)\n",
    "        new_all_GT_mult.append(new_event_mult)\n",
    "    \n",
    "    # Convert to awkward arrays\n",
    "    return ak.Array(new_all_GT_ind), ak.Array(new_all_GT_mult)\n",
    "#GT_ind, GT_mult = filter_repeated_indexes_for_events(GT_ind, GT_mult)\n",
    "\n",
    "import awkward as ak\n",
    "\n",
    "# Create new lists to store the filtered results\n",
    "# This makes sure GT_ind, MT_ind, Recon_ind have the same indices\n",
    "filtered_GT_ind = []\n",
    "filtered_GT_mult = []\n",
    "filtered_MT_ind = []\n",
    "\n",
    "\n",
    "for event_idx, track_indices in enumerate(Track_ind):\n",
    "    # Flatten the current event's track indices and convert to a set\n",
    "    track_flat = set(ak.flatten(track_indices).tolist())  # Ensure it contains only integers\n",
    "    \n",
    "    # Filter GT_ind and GT_mult for the current event, preserving structure\n",
    "    event_GT_ind = GT_ind[event_idx]\n",
    "    event_GT_mult = GT_mult[event_idx]\n",
    "    filtered_event_GT_ind = []\n",
    "    filtered_event_GT_mult = []\n",
    "    for sublist_ind, sublist_mult in zip(event_GT_ind, event_GT_mult):\n",
    "        filtered_sublist_ind = [idx for idx in sublist_ind if idx in track_flat]\n",
    "        filtered_sublist_mult = [mult for idx, mult in zip(sublist_ind, sublist_mult) if idx in track_flat]\n",
    "        filtered_event_GT_ind.append(filtered_sublist_ind)\n",
    "        filtered_event_GT_mult.append(filtered_sublist_mult)\n",
    "\n",
    "    # Filter MT_ind for the current event, preserving structure\n",
    "    event_MT_ind = MT_ind[event_idx]\n",
    "    filtered_event_MT_ind = []\n",
    "    for sublist in event_MT_ind:\n",
    "        filtered_sublist = [idx for idx in sublist if idx in track_flat]\n",
    "        filtered_event_MT_ind.append(filtered_sublist)\n",
    "\n",
    "    # Append filtered results\n",
    "    filtered_GT_ind.append(filtered_event_GT_ind)\n",
    "    filtered_GT_mult.append(filtered_event_GT_mult)\n",
    "    filtered_MT_ind.append(filtered_event_MT_ind)\n",
    "\n",
    "# Convert the filtered results back to awkward arrays\n",
    "GT_ind_filt = ak.Array(filtered_GT_ind)\n",
    "GT_mult_filt = ak.Array(filtered_GT_mult)\n",
    "MT_ind_filt = ak.Array(filtered_MT_ind)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "def calculate_all_event_scores(GT_ind, energies, recon_ind, RegressedEnergy, multi, num_events = 100):\n",
    "    \"\"\"\n",
    "    Calculate sim-to-reco and reco-to-sim scores for all CaloParticle and ReconstructedTrackster combinations across all events.\n",
    "\n",
    "    Parameters:\n",
    "    - GT_ind: List of CaloParticle indices for all events.\n",
    "    - energies: List of energy arrays for all events.\n",
    "    - recon_ind: List of ReconstructedTrackster indices for all events.\n",
    "    - LC_x, LC_y, LC_z, LC_eta: Lists of x, y, z positions and eta values for all DetIds across events.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing scores and additional features for each CaloParticle-Trackster combination across all events.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store results\n",
    "    all_results = []\n",
    "\n",
    "    # Loop over all events with a progress bar\n",
    "    for event_index in tqdm(range(num_events)):\n",
    "        caloparticles = GT_ind[event_index]  # Indices for all CaloParticles in the event\n",
    "        tracksters = recon_ind[event_index]  # Indices for all ReconstructedTracksters in the event\n",
    "        event_energies = energies[event_index]  # Energies for this event\n",
    "        TrueEnergy = round(RegressedEnergy[event_index][0])\n",
    "        trackster_det_id_sets = [set(trackster) for trackster in tracksters]\n",
    "        event_multi = multi[event_index]\n",
    "        # Loop over all CaloParticles\n",
    "        for calo_idx, caloparticle in enumerate(caloparticles):\n",
    "            Calo_multi = event_multi[calo_idx]\n",
    "\n",
    "            calo_det_ids = set(calo_id for calo_id in caloparticle)\n",
    "            # Loop over all Tracksters\n",
    "            for trackster_idx, trackster in enumerate(tracksters):\n",
    "                # Calculate sim-to-reco score\n",
    "                trackster_det_ids = trackster_det_id_sets[trackster_idx]\n",
    "                shared_det_ids = calo_det_ids.intersection(trackster_det_ids)\n",
    "                \n",
    "\n",
    "                # Calculate shared_energy by summing energies of shared det_ids\n",
    "                shared_energy = np.sum(event_energies[list(shared_det_ids)]) if shared_det_ids else 0.0\n",
    "                \n",
    "\n",
    "\n",
    "                cp_energy = TrueEnergy\n",
    "                \n",
    "                trackster_energy = np.sum([event_energies[det_id] for det_id in trackster])\n",
    "\n",
    "                # Calculate energy difference ratio\n",
    "                energy_diff_ratio = (trackster_energy / cp_energy if cp_energy != 0 else None)\n",
    "\n",
    "                # Append results\n",
    "                all_results.append({\n",
    "                    \"event_index\": event_index,\n",
    "                    \"cp_id\": calo_idx,\n",
    "                    \"trackster_id\": trackster_idx,\n",
    "                    \"cp_energy\": cp_energy,\n",
    "                    \"trackster_energy\": trackster_energy,\n",
    "                    \"energy_ratio\": energy_diff_ratio,\n",
    "                    \"shared_energy\": shared_energy  # New column\n",
    "                })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return df\n",
    "\n",
    "recon_ind = []\n",
    "\n",
    "for event_idx, labels in enumerate(all_cluster_labels):\n",
    "\n",
    "    event_clusters = {} \n",
    "    \n",
    "    for cluster_idx, cluster_label in enumerate(labels):\n",
    "        if cluster_label not in event_clusters:\n",
    "            event_clusters[cluster_label] = []\n",
    "        event_clusters[cluster_label].extend(Track_ind[event_idx][cluster_idx])\n",
    "    \n",
    "    recon_ind.append([event_clusters[label] for label in sorted(event_clusters.keys())])\n",
    "recon_ind = ak.Array(recon_ind)\n",
    "recon_mult = ak.Array([[[1 for _ in sublist] for sublist in event] for event in recon_ind]) # keep variable for future\n",
    "# endeavours where the model is able to assign multiple caloparticles to a LC.\n",
    "Track_mult = ak.Array([[[1 for _ in sublist] for sublist in event] for event in Track_ind]) # keep variable for future\n",
    "MT_mult_filt = ak.Array([[[1 for _ in sublist] for sublist in event] for event in MT_ind_filt]) # keep variable for future\n",
    "#4.2 Make DF from our model and CERN\n",
    "\n",
    "df_CL = calculate_all_event_scores(GT_ind_filt, energies, recon_ind, TrueEnergy, GT_mult_filt, num_events = len(recon_ind))\n",
    "df_CL.to_csv('df_Trans_pi_res.csv', index=False)\n",
    "df_TICL = calculate_all_event_scores(GT_ind_filt, energies, MT_ind_filt, TrueEnergy, GT_mult_filt, num_events = len(recon_ind))\n",
    "\n",
    "df_TICL.to_csv('df_MT_pi_res.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30105a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
